"""
æ··åˆæ–‡æ¡£å¤„ç†å™¨ - æ”¯æŒæ–‡æœ¬æå–å’ŒOCRåŒè·¯å¾„

æ ¹æ®PDFçš„æ–‡æœ¬å±‚æƒ…å†µï¼Œè‡ªåŠ¨é€‰æ‹©ï¼š
- Fast Path: ç›´æ¥æ–‡æœ¬æå–ï¼ˆæœ‰æ–‡æœ¬å±‚ï¼‰
- OCR Path: PaddleOCRè¯†åˆ«ï¼ˆæ— /å°‘æ–‡æœ¬å±‚ï¼‰
"""
import asyncio
import time
from typing import Dict, Any, Optional, Callable
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import text

from app.core.ocr_engine import get_ocr_engine
from app.utils.pdf_validator import validate_pdf_before_upload
from app.services.document_processor import DocumentProcessor
from app.core.logging_config import get_logger

logger = get_logger(__name__)


class HybridDocumentProcessor:
    """æ··åˆæ–‡æ¡£å¤„ç†å™¨"""

    def __init__(self):
        self.ocr_engine = get_ocr_engine()
        self.text_processor = DocumentProcessor()

        # é…ç½®é˜ˆå€¼
        self.TEXT_RATIO_THRESHOLD = 0.1  # æ–‡æœ¬é¡µå æ¯”é˜ˆå€¼
        self.OCR_CONFIDENCE_THRESHOLD = 0.6  # OCR ç½®ä¿¡åº¦é˜ˆå€¼

    async def process_document(
        self,
        file_path: str,
        document_id: int,
        user_id: int,
        title: str,
        db: AsyncSession,
        progress_callback: Optional[Callable[[str, int, int], None]] = None
    ) -> Dict[str, Any]:
        """
        æ··åˆå¤„ç†æ–‡æ¡£

        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            document_id: æ–‡æ¡£ID
            user_id: ç”¨æˆ·ID
            title: æ–‡æ¡£æ ‡é¢˜
            db: æ•°æ®åº“ä¼šè¯
            progress_callback: è¿›åº¦å›è°ƒ callback(stage, current, total)
                              stage: 'detecting' | 'extracting' | 'ocr' | 'vectorizing' | 'completed'

        Returns:
            {
                'success': bool,
                'path': 'fast' | 'ocr',
                'text_ratio': float,
                'ocr_confidence': float,
                'processing_time': float,
                'chunks': int,
                'message': str
            }
        """
        import time
        start_time = time.time()

        try:
            # ========== é˜¶æ®µ1: æ£€æµ‹ ==========
            if progress_callback:
                progress_callback('detecting', 0, 1)

            logger.info("="*60)
            logger.info("ğŸ” é˜¶æ®µ 1/4: æ£€æµ‹ PDF ç±»å‹")
            logger.info("="*60)

            validation = validate_pdf_before_upload(file_path)

            logger.info(
                f"ğŸ“Š æ£€æµ‹ç»“æœ: "
                f"æ€»é¡µæ•°={validation['total_pages']}, "
                f"æ–‡æœ¬é¡µ={validation['text_pages']}, "
                f"æ–‡æœ¬å æ¯”={validation['text_ratio']:.1%}, "
                f"æ˜¯å¦æ‰«æç‰ˆ={'æ˜¯' if validation['is_scan'] else 'å¦'}"
            )

            # æ›´æ–°æ•°æ®åº“ï¼šè®°å½•æ£€æµ‹ç»“æœ
            await self._update_document_status(
                db, document_id,
                has_text_layer=not validation['is_scan'],
                current_page=0,
                total_pages=validation['total_pages']
            )

            # ========== è·¯å¾„é€‰æ‹© ==========
            if validation['text_ratio'] >= self.TEXT_RATIO_THRESHOLD:
                # âœ… Fast Path: æœ‰è¶³å¤Ÿæ–‡æœ¬å±‚
                return await self._fast_path(
                    file_path, document_id, user_id, title, db,
                    validation, progress_callback, start_time
                )
            else:
                # â±ï¸ OCR Path: éœ€è¦OCRå¤„ç†
                return await self._ocr_path(
                    file_path, document_id, user_id, title, db,
                    validation, progress_callback, start_time
                )

        except Exception as e:
            logger.error(f"âŒ æ–‡æ¡£å¤„ç†å¤±è´¥: {e}", exc_info=True)

            # æ›´æ–°çŠ¶æ€ä¸ºå¤±è´¥
            await self._update_document_status(
                db, document_id,
                processing_status='failed'
            )

            return {
                'success': False,
                'error': str(e),
                'message': f'æ–‡æ¡£å¤„ç†å¤±è´¥: {str(e)}'
            }

    async def _fast_path(
        self,
        file_path: str,
        document_id: int,
        user_id: int,
        title: str,
        db: AsyncSession,
        validation: Dict[str, Any],
        progress_callback: Optional[Callable],
        start_time: float
    ) -> Dict[str, Any]:
        """å¿«é€Ÿè·¯å¾„ï¼šç›´æ¥æå–æ–‡æœ¬"""

        logger.info(f"âœ… é€‰æ‹©å¿«é€Ÿè·¯å¾„ï¼ˆFast Pathï¼‰ï¼šPDF æœ‰ {validation['text_ratio']:.1%} çš„é¡µé¢åŒ…å«æ–‡æœ¬å±‚")

        try:
            # ========== é˜¶æ®µ2: æå–æ–‡æœ¬ ==========
            if progress_callback:
                progress_callback('extracting', 1, 3)

            logger.info("ğŸ“– é˜¶æ®µ 2/4: æå–æ–‡æœ¬ï¼ˆå¿«é€Ÿè·¯å¾„ï¼‰")

            # ä½¿ç”¨ç°æœ‰çš„å¤„ç†å™¨
            from app.services.document_processor import process_uploaded_document
            result = await process_uploaded_document(
                file_path=file_path,
                title=title,
                user_email=""  # è¿™ä¸ªå‚æ•°æš‚æ—¶ä¸ç”¨
            )

            # ========== é˜¶æ®µ3: æå–ç›®å½•å¹¶åˆ’åˆ†ç« èŠ‚ ==========
            if progress_callback:
                progress_callback('extracting_toc', 2, 4)

            logger.info("ğŸ“š é˜¶æ®µ 3/4: æå–ç›®å½•å¹¶åˆ’åˆ†ç« èŠ‚")

            # æå–ç›®å½•ï¼ˆä½¿ç”¨TextbookParserï¼‰
            toc_text = ""
            try:
                from app.core.textbook_parser import TextbookParser
                parser = TextbookParser()

                parse_result = await parser.parse_textbook(file_path, db)
                toc_text = parse_result.get('toc_text', '')

                source = parse_result.get('source', 'unknown')
                pages = parse_result.get('pages', [])

                logger.info(
                    f"   ç›®å½•æå–å®Œæˆ: "
                    f"æ¥æº={source}, "
                    f"é¡µç ={pages}, "
                    f"æ–‡æœ¬é•¿åº¦={len(toc_text)}å­—ç¬¦"
                )
            except Exception as e:
                logger.warning(f"   âš ï¸  ç›®å½•æå–å¤±è´¥: {e}ï¼Œä½¿ç”¨æ–‡æœ¬å‰3ä¸ªchunks")
                # Fallback: ä½¿ç”¨å‰3ä¸ªchunks
                toc_text = "\n\n".join([c.page_content for c in result.get('chunks', [])[:3]])

            # åˆ’åˆ†ç« èŠ‚ï¼ˆä½¿ç”¨æ”¹è¿›ç‰ˆæå–å™¨ï¼‰
            chapters_count = 0
            try:
                from app.services.improved_chapter_extractor import ImprovedChapterExtractor

                extractor = ImprovedChapterExtractor()

                if toc_text:
                    logger.info(f"   å¼€å§‹æ™ºèƒ½æå–ç« èŠ‚ï¼Œç›®å½•æ–‡æœ¬é•¿åº¦: {len(toc_text)} å­—ç¬¦")

                    # ğŸ”§ FIX: ä½¿ç”¨ç›´æ¥æ–‡æœ¬æå–æ–¹æ³•ï¼Œä¸éœ€è¦é¡µé¢æ£€æµ‹
                    chapters = await extractor.extract_chapters_from_text(
                        toc_text=toc_text,
                        document_id=document_id,
                        user_id=user_id,
                        db=db
                    )

                    chapters_count = len(chapters)
                    logger.info(f"   âœ… æˆåŠŸåˆ’åˆ† {chapters_count} ä¸ªç« èŠ‚")
                else:
                    logger.warning("   âš ï¸  æ²¡æœ‰ç›®å½•æ–‡æœ¬ï¼Œè·³è¿‡ç« èŠ‚åˆ’åˆ†")

            except Exception as e:
                logger.error(f"   âŒ ç« èŠ‚åˆ’åˆ†å¤±è´¥: {e}", exc_info=True)

            # ========== é˜¶æ®µ4: å®Œæˆ ==========
            if progress_callback:
                progress_callback('completed', 4, 4)

            logger.info("ğŸ§  é˜¶æ®µ 4/4: å‘é‡åŒ–å¹¶å­˜å‚¨")

            # å‘é‡åŒ–å·²ç»åœ¨ process_uploaded_document ä¸­å®Œæˆ
            chunks = result.get('chunks', [])

            processing_time = time.time() - start_time

            # æ›´æ–°çŠ¶æ€ï¼ˆåŒ…æ‹¬ç« èŠ‚æ•°ï¼‰
            await self._update_document_status(
                db, document_id,
                processing_status='completed',
                ocr_confidence=1.0,  # æ–‡æœ¬æå–çš„ç½®ä¿¡åº¦ä¸º100%
                total_chapters=chapters_count  # æ›´æ–°ç« èŠ‚æ•°
            )

            logger.info(
                f"âœ… å¤„ç†å®Œæˆï¼ˆå¿«é€Ÿè·¯å¾„ï¼‰ï¼š"
                f"è€—æ—¶={processing_time:.1f}ç§’, "
                f"Chunks={len(chunks)}"
            )

            return {
                'success': True,
                'path': 'fast',
                'text_ratio': validation['text_ratio'],
                'ocr_confidence': 1.0,
                'processing_time': processing_time,
                'chunks': len(chunks),
                'message': f'âœ… æ–‡æ¡£å¤„ç†å®Œæˆï¼ˆå¿«é€Ÿè·¯å¾„ï¼‰ï¼Œè€—æ—¶ {processing_time:.1f}ç§’'
            }

        except Exception as e:
            await self._update_document_status(
                db, document_id,
                processing_status='failed'
            )
            raise

    async def _ocr_path(
        self,
        file_path: str,
        document_id: int,
        user_id: int,
        title: str,
        db: AsyncSession,
        validation: Dict[str, Any],
        progress_callback: Optional[Callable],
        start_time: float
    ) -> Dict[str, Any]:
        """
        OCRè·¯å¾„ï¼šæ™ºèƒ½å¤„ç†æ‰«æç‰ˆ PDF

        ä¸‰æ­¥èµ°ç­–ç•¥ï¼š
        1. å…ˆå°è¯•æå– PDF ä¹¦ç­¾ï¼ˆä¸éœ€è¦ OCRï¼ï¼‰
        2. å¦‚æœæ²¡æœ‰ä¹¦ç­¾ï¼Œå¯å‘å¼ OCR å‰ 60 é¡µå¹¶æ™ºèƒ½ç­›é€‰ç›®å½•é¡µ
        3. ç”¨ LLM åˆ’åˆ†ç« èŠ‚

        è¿™æ ·æœ€å¤šåªéœ€è¦ OCR 60 é¡µï¼Œè€Œä¸æ˜¯æ•´æœ¬ä¹¦ 424 é¡µ
        """

        logger.info(f"â±ï¸  é€‰æ‹© OCR è·¯å¾„ï¼ˆOCR Pathï¼‰ï¼šæ‰«æç‰ˆ PDFï¼Œæ™ºèƒ½æå–ç›®å½•")

        try:
            # æ›´æ–°çŠ¶æ€ä¸ºå¤„ç†ä¸­
            await self._update_document_status(
                db, document_id,
                processing_status='ocr_processing',
                total_pages=validation['total_pages']
            )

            # ========== ç¬¬ä¸€æ­¥ï¼šå°è¯•æå– PDF ä¹¦ç­¾ï¼ˆä¸éœ€è¦ OCRï¼ï¼‰==========
            logger.info("ğŸ“š ç¬¬ä¸€æ­¥ï¼šå°è¯•æå– PDF ä¹¦ç­¾...")

            toc_text = ""
            toc_source = "unknown"
            ocr_confidence = 0.0

            try:
                import fitz
                doc = fitz.open(file_path)
                toc = doc.get_toc()

                if toc and len(toc) > 0:
                    logger.info(f"   âœ… æ‰¾åˆ° {len(toc)} ä¸ªä¹¦ç­¾ï¼ä¸éœ€è¦ OCR")

                    # æ„å»ºç›®å½•æ–‡æœ¬
                    toc_parts = []
                    for level, title, page_num in toc:
                        indent = "  " * (level - 1)
                        toc_parts.append(f"{indent}{'â€¢' * level} {title} (ç¬¬{page_num}é¡µ)")

                    toc_text = "\n".join(toc_parts)
                    toc_source = "bookmark"
                    ocr_confidence = 1.0  # ä¹¦ç­¾ä¸éœ€è¦ OCRï¼Œç½®ä¿¡åº¦ä¸º 100%
                    doc.close()
                else:
                    logger.info("   âš ï¸  æ²¡æœ‰ä¹¦ç­¾ï¼Œéœ€è¦ OCR æå–ç›®å½•")
                    doc.close()

            except Exception as e:
                logger.warning(f"   âš ï¸  ä¹¦ç­¾æå–å¤±è´¥: {e}ï¼Œå°†ä½¿ç”¨ OCR")

            # ========== ç¬¬äºŒæ­¥ï¼šå¦‚æœæ²¡æœ‰ä¹¦ç­¾ï¼Œå¯å‘å¼ OCR å‰ 60 é¡µ ==========
            if not toc_text:
                MAX_SCAN_PAGES = 60
                pages_to_ocr = list(range(1, min(MAX_SCAN_PAGES + 1, validation['total_pages'] + 1)))

                logger.info(f"ğŸ”¬ ç¬¬äºŒæ­¥ï¼šå¯å‘å¼ OCR è¯†åˆ«å‰ {len(pages_to_ocr)} é¡µ...")

                if progress_callback:
                    progress_callback('ocr', 0, len(pages_to_ocr))

                # æ›´æ–°æ€»é¡µæ•°
                await self._update_document_status(
                    db, document_id,
                    total_pages=len(pages_to_ocr)
                )

                # è¿›åº¦å›è°ƒ
                def ocr_progress(current: int, total: int, message: str):
                    logger.info(f"   {message}")
                    if progress_callback:
                        progress_callback('ocr', current, len(pages_to_ocr))

                    # æ¯å¤„ç† 5 é¡µæ›´æ–°ä¸€æ¬¡æ•°æ®åº“
                    if current % 5 == 0:
                        try:
                            loop = asyncio.get_running_loop()
                            loop.call_soon_threadsafe(
                                lambda: asyncio.create_task(
                                    self._update_document_status(
                                        db, document_id,
                                        current_page=current
                                    )
                                )
                            )
                        except RuntimeError:
                            pass

                # ğŸ”§ FIX: ä½¿ç”¨ asyncio.to_thread å°†åŒæ­¥ OCR ç§»åˆ°çº¿ç¨‹æ± 
                # è¿™æ ·å…¶ä»– API è¯·æ±‚ä¸ä¼šè¢«é˜»å¡
                import asyncio

                ocr_result = await asyncio.to_thread(
                    self.ocr_engine.process_pdf,
                    pdf_path=file_path,
                    pages=pages_to_ocr,
                    progress_callback=ocr_progress
                )

                if not ocr_result['success']:
                    raise Exception(f"OCR å¤„ç†å¤±è´¥: {ocr_result['errors']}")

                ocr_confidence = ocr_result['avg_confidence']
                logger.info(f"   âœ… OCR å®Œæˆï¼Œè¯†åˆ«äº† {len(ocr_result['pages'])} é¡µï¼Œç½®ä¿¡åº¦ {ocr_confidence:.1%}")

                # ========== æ™ºèƒ½ç­›é€‰ï¼šæ‰¾å‡ºæœ€å¯èƒ½æ˜¯ç›®å½•çš„é¡µ ==========
                logger.info("ğŸ” ç¬¬ä¸‰æ­¥ï¼šæ™ºèƒ½ç­›é€‰ç›®å½•é¡µ...")

                # å¯¼å…¥ TextbookParser çš„è¯„åˆ†é€»è¾‘
                from app.core.textbook_parser import TextbookParser
                parser = TextbookParser()

                # ğŸ”§ FIX: å¯¹æ¯ä¸€é¡µè¯„åˆ†ï¼Œä½¿ç”¨ä¸Fast Pathç›¸åŒçš„é€»è¾‘
                page_scores = []
                for page_data in ocr_result['pages']:
                    text = page_data['text']
                    page_num = page_data['page_num']

                    if text.strip():
                        score = parser._calculate_page_score(text, page_num - 1)
                        # ä¿å­˜æ‰€æœ‰é¡µé¢ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ–‡æœ¬
                        page_scores.append({
                            'page': page_num,
                            'score': score,
                            'text': text,
                            'char_count': len(text)
                        })

                        # æ˜¾ç¤ºå‰10é¡µçš„åˆ†æ•°
                        if page_num <= 10:
                            status = "âœ…" if score > 20 else "  "
                            logger.info(f"   {status} ç¬¬ {page_num:2} é¡µ: {score:3} åˆ† | {len(text):4} å­—ç¬¦")

                if page_scores:
                    # ğŸ”§ FIX: ä½¿ç”¨ä¿®å¤åçš„è¿ç»­æ€§æ£€æŸ¥é€»è¾‘
                    # å°†æ•°æ®è½¬æ¢ä¸º _select_best_pages éœ€è¦çš„æ ¼å¼
                    best_pages = parser._select_best_pages(page_scores)

                    logger.info(f"   âœ… é€‰å®š {len(best_pages)} ä¸ªç›®å½•é¡µ: {[p['page'] for p in best_pages]}")

                    # åˆå¹¶æ–‡æœ¬
                    toc_text = "\n\n".join([
                        f"--- ç¬¬{p['page']}é¡µ ---\n{p['text']}"
                        for p in best_pages
                    ])
                    toc_source = "ocr_scan"

                    # æ˜¾ç¤ºé€‰æ‹©ç»“æœçš„è¯¦ç»†ä¿¡æ¯
                    logger.info(f"   ğŸ“Š ç›®å½•æ–‡æœ¬æ€»é•¿åº¦: {len(toc_text)} å­—ç¬¦")
                else:
                    # Fallback: ä½¿ç”¨æ‰€æœ‰ OCR æ–‡æœ¬
                    logger.warning("   âš ï¸  æœªæ‰¾åˆ°æ˜æ˜¾ç›®å½•é¡µï¼Œä½¿ç”¨æ‰€æœ‰ OCR æ–‡æœ¬")
                    toc_text = ocr_result['full_text']
                    toc_source = "ocr_fallback"

            # ========== ç¬¬ä¸‰æ­¥ï¼šä½¿ç”¨æ”¹è¿›ç‰ˆç« èŠ‚æå–å™¨ ==========
            if progress_callback:
                progress_callback('processing', 1, 3)

            logger.info(f"ğŸ§  ç¬¬ä¸‰æ­¥ï¼šä½¿ç”¨æ”¹è¿›ç‰ˆç« èŠ‚æå–å™¨ï¼ˆç›®å½•æ¥æº: {toc_source}ï¼‰")
            logger.info(f"   ç›®å½•æ–‡æœ¬é•¿åº¦: {len(toc_text)} å­—ç¬¦")

            chapters_count = 0
            try:
                from app.services.improved_chapter_extractor import ImprovedChapterExtractor

                extractor = ImprovedChapterExtractor()

                logger.info("ğŸ“š å¼€å§‹æ™ºèƒ½æå–ç« èŠ‚...")

                # ğŸ”§ FIX: OCRè·¯å¾„å·²ç»æœ‰é€‰æ‹©å¥½çš„ç›®å½•æ–‡æœ¬ï¼Œç›´æ¥ä½¿ç”¨ extract_chapters_from_text
                if toc_text and len(toc_text) > 100:
                    logger.info(f"   ä½¿ç”¨é¢„é€‰çš„ç›®å½•æ–‡æœ¬è¿›è¡Œç« èŠ‚æå–")
                    chapters = await extractor.extract_chapters_from_text(
                        toc_text=toc_text,
                        document_id=document_id,
                        user_id=user_id,
                        db=db
                    )
                else:
                    # Fallback: å¦‚æœæ²¡æœ‰è¶³å¤Ÿçš„ç›®å½•æ–‡æœ¬ï¼Œå°è¯•ä»OCRç»“æœé‡æ–°æå–
                    logger.warning(f"   âš ï¸  ç›®å½•æ–‡æœ¬å¤ªçŸ­ï¼ˆ{len(toc_text)}å­—ç¬¦ï¼‰ï¼Œå°è¯•ä»OCRç»“æœé‡æ–°æå–")
                    chapters = await extractor.extract_chapters(
                        ocr_result=ocr_result,
                        file_path=file_path,
                        document_id=document_id,
                        user_id=user_id,
                        db=db
                    )

                chapters_count = len(chapters) if chapters else 0
                logger.info(f"âœ… æˆåŠŸæå– {chapters_count} ä¸ªç« èŠ‚")

                # æ‰“å°ç« èŠ‚åˆ—è¡¨
                if chapters:
                    logger.info("ğŸ“š æå–çš„ç« èŠ‚åˆ—è¡¨:")
                    for ch in chapters:
                        subs = ch.get('subsections', [])
                        logger.info(f"   ç¬¬{ch['chapter_number']}ç« : {ch['chapter_title']} ({len(subs)}ä¸ªå°èŠ‚)")

            except Exception as e:
                logger.warning(f"âš ï¸  ç« èŠ‚æå–å¤±è´¥: {e}", exc_info=True)
                import traceback
                traceback.print_exc()

            processing_time = time.time() - start_time

            # ========== å®Œæˆ ==========
            if progress_callback:
                progress_callback('completed', 3, 3)

            # æ›´æ–°çŠ¶æ€
            await self._update_document_status(
                db, document_id,
                processing_status='completed',
                ocr_confidence=ocr_confidence,
                total_chapters=chapters_count
            )

            logger.info(
                f"âœ… OCR å¤„ç†å®Œæˆ: "
                f"è€—æ—¶={processing_time:.1f}ç§’, "
                f"ç›®å½•æ¥æº={toc_source}, "
                f"ç½®ä¿¡åº¦={ocr_confidence:.1%}, "
                f"ç« èŠ‚æ•°={chapters_count}"
            )

            return {
                'success': True,
                'path': 'ocr',
                'text_ratio': validation['text_ratio'],
                'ocr_confidence': ocr_confidence,
                'processing_time': processing_time,
                'chunks': 0,
                'toc_source': toc_source,
                'message': f'âœ… å¤„ç†å®Œæˆï¼ˆ{toc_source}ï¼‰ï¼Œ{chapters_count} ä¸ªç« èŠ‚ï¼Œè€—æ—¶ {processing_time:.1f}ç§’'
            }

        except Exception as e:
            logger.error(f"âŒ OCR å¤„ç†å¤±è´¥: {e}", exc_info=True)
            await self._update_document_status(
                db, document_id,
                processing_status='failed'
            )
            raise

    async def _update_document_status(
        self,
        db: AsyncSession,
        document_id: int,
        processing_status: Optional[str] = None,
        has_text_layer: Optional[bool] = None,
        ocr_confidence: Optional[float] = None,
        current_page: Optional[int] = None,
        total_pages: Optional[int] = None,
        total_chapters: Optional[int] = None
    ):
        """æ›´æ–°æ–‡æ¡£å¤„ç†çŠ¶æ€"""
        updates = []
        params = {'document_id': document_id}

        if processing_status is not None:
            updates.append('processing_status = :processing_status')
            params['processing_status'] = processing_status

        if has_text_layer is not None:
            updates.append('has_text_layer = :has_text_layer')
            params['has_text_layer'] = has_text_layer

        if ocr_confidence is not None:
            updates.append('ocr_confidence = :ocr_confidence')
            params['ocr_confidence'] = ocr_confidence

        if current_page is not None:
            updates.append('current_page = :current_page')
            params['current_page'] = current_page

        if total_pages is not None:
            updates.append('total_pages = :total_pages')
            params['total_pages'] = total_pages

        if total_chapters is not None:
            updates.append('total_chapters = :total_chapters')
            params['total_chapters'] = total_chapters

        if updates:
            query = text(f"""
                UPDATE documents
                SET {', '.join(updates)}
                WHERE id = :document_id
            """)
            await db.execute(query, params)
            await db.commit()
