"""
æ™ºèƒ½ç« èŠ‚æå–å™¨ - å¤šç­–ç•¥ã€å¤šå±‚æ¬¡æå–ç›®å½•

æ ¸å¿ƒæ”¹è¿›ï¼š
1. æ‰©å¤§æœç´¢èŒƒå›´ï¼šæ‰«æå‰ 150 é¡µï¼ˆè€Œä¸æ˜¯ 60ï¼‰
2. æ™ºèƒ½ç›®å½•å®šä½ï¼šæ‰¾åˆ°"ç›®å½•"æ ‡é¢˜é¡µ
3. è¿ç»­æ€§æ£€æµ‹ï¼šç›®å½•é€šå¸¸æ˜¯è¿ç»­çš„å‡ é¡µ
4. æ•°é‡éªŒè¯ï¼šç« èŠ‚æ•°é‡åº”è¯¥åˆç†ï¼ˆ3-20ç« ï¼‰
5. äºŒæ¬¡æå–ï¼šå¦‚æœç¬¬ä¸€æ¬¡æå–å¤ªå°‘ï¼Œå°è¯•æ›´å¤šé¡µé¢
"""
import re
import json
from typing import List, Dict, Any, Optional
from sqlalchemy.ext.asyncio import AsyncSession

from app.core.config import settings


class SmartChapterExtractor:
    """æ™ºèƒ½ç« èŠ‚æå–å™¨"""

    def __init__(self):
        self.api_key = settings.DASHSCOPE_API_KEY
        self.model = "qwen-max"

        # æ‰©å±•çš„æ‰«æèŒƒå›´
        self.MAX_SCAN_PAGES = 150  # ä» 60 å¢åŠ åˆ° 150

    async def extract_chapters(
        self,
        file_path: str,
        document_id: int,
        user_id: int,
        db: AsyncSession,
        ocr_result: Optional[Dict[str, Any]] = None
    ) -> List[Dict[str, Any]]:
        """
        æ™ºèƒ½æå–ç« èŠ‚ï¼ˆå¤šç­–ç•¥ï¼‰

        ç­–ç•¥ä¼˜å…ˆçº§ï¼š
        1. PDF ä¹¦ç­¾ï¼ˆæœ€å‡†ç¡®ï¼‰
        2. æ™ºèƒ½å®šä½ç›®å½•é¡µï¼ˆOCRï¼‰
        3. æ‰©å¤§èŒƒå›´é‡è¯•
        4. Fallbackï¼šå…¨æ–‡æ¡£æå–
        """

        print(f"\n{'='*70}")
        print(f"ğŸ§  æ™ºèƒ½ç« èŠ‚æå–å™¨å¯åŠ¨")
        print(f"{'='*70}\n")

        # ========== ç­–ç•¥ 1ï¼šPDF ä¹¦ç­¾ ==========
        print("ğŸ“š ç­–ç•¥ 1/4: å°è¯•æå– PDF ä¹¦ç­¾...")
        bookmark_result = await self._try_extract_bookmarks(file_path, document_id, user_id, db)
        if bookmark_result:
            return bookmark_result

        # ========== ç­–ç•¥ 2ï¼šæ™ºèƒ½å®šä½ç›®å½•é¡µ ==========
        print("\nğŸ” ç­–ç•¥ 2/4: æ™ºèƒ½å®šä½ç›®å½•é¡µ...")
        if ocr_result:
            located_result = await self._locate_toc_pages_smart(ocr_result, file_path, document_id, user_id, db)
            if located_result and self._validate_chapter_count(located_result):
                return located_result

        # ========== ç­–ç•¥ 3ï¼šæ‰©å¤§èŒƒå›´é‡è¯• ==========
        print("\nğŸ”„ ç­–ç•¥ 3/4: æ‰©å¤§èŒƒå›´é‡è¯•...")
        extended_result = await self._extended_range_extraction(file_path, document_id, user_id, db)
        if extended_result and self._validate_chapter_count(extended_result):
            return extended_result

        # ========== ç­–ç•¥ 4ï¼šFallback ==========
        print("\nâš ï¸  ç­–ç•¥ 4/4: ä½¿ç”¨å¯å‘å¼ Fallback...")
        return await self._heuristic_fallback(file_path, document_id, user_id, db)

    async def _try_extract_bookmarks(
        self,
        file_path: str,
        document_id: int,
        user_id: int,
        db: AsyncSession
    ) -> Optional[List[Dict[str, Any]]]:
        """ç­–ç•¥ 1ï¼šæå– PDF ä¹¦ç­¾"""
        try:
            import fitz
            doc = fitz.open(file_path)
            toc = doc.get_toc()
            doc.close()

            if not toc or len(toc) < 3:
                print(f"   âŒ ä¹¦ç­¾å¤ªå°‘æˆ–ä¸å­˜åœ¨ï¼ˆ{len(toc) if toc else 0} ä¸ªï¼‰")
                return None

            print(f"   âœ… æ‰¾åˆ° {len(toc)} ä¸ªä¹¦ç­¾")

            # ä½¿ç”¨ LLM æ¸…æ´—å’Œç»“æ„åŒ–ä¹¦ç­¾
            toc_text = self._format_bookmarks(toc)

            chapters = await self._llm_extract_from_toc(toc_text, document_id, user_id, db)

            if chapters and len(chapters) >= 3:
                print(f"   âœ… ä»ä¹¦ç­¾æå–äº† {len(chapters)} ä¸ªç« èŠ‚")
                return chapters
            else:
                print(f"   âš ï¸  ä¹¦ç­¾æå–çš„ç« èŠ‚æ•°å¤ªå°‘ï¼ˆ{len(chapters)}ï¼‰")
                return None

        except Exception as e:
            print(f"   âŒ ä¹¦ç­¾æå–å¤±è´¥: {e}")
            return None

    async def _locate_toc_pages_smart(
        self,
        ocr_result: Dict[str, Any],
        file_path: str,
        document_id: int,
        user_id: int,
        db: AsyncSession
    ) -> Optional[List[Dict[str, Any]]]:
        """ç­–ç•¥ 2ï¼šæ™ºèƒ½å®šä½ç›®å½•é¡µ"""

        pages = ocr_result.get('pages', [])

        if not pages:
            print(f"   âŒ æ²¡æœ‰ OCR é¡µé¢")
            return None

        print(f"   ğŸ“„ åˆ†æ {len(pages)} ä¸ª OCR é¡µé¢...")

        # æ­¥éª¤ 1ï¼šæ‰¾åˆ°"ç›®å½•"æ ‡é¢˜é¡µ
        toc_start_page = self._find_toc_start_page(pages)

        if toc_start_page is None:
            print(f"   âš ï¸  æœªæ‰¾åˆ°æ˜ç¡®çš„ç›®å½•èµ·å§‹é¡µ")
            return None

        print(f"   âœ… ç›®å½•èµ·å§‹é¡µï¼šç¬¬ {toc_start_page} é¡µ")

        # æ­¥éª¤ 2ï¼šä»èµ·å§‹é¡µå¼€å§‹ï¼Œå–è¿ç»­çš„ç›®å½•é¡µï¼ˆé€šå¸¸ 3-10 é¡µï¼‰
        toc_pages = self._extract_continuous_toc_pages(pages, toc_start_page)

        print(f"   ğŸ“– æå–äº† {len(toc_pages)} ä¸ªè¿ç»­ç›®å½•é¡µ")

        # æ­¥éª¤ 3ï¼šåˆå¹¶æ–‡æœ¬
        toc_text = "\n\n".join([
            f"--- ç¬¬{p['page']}é¡µ ---\n{p['text']}"
            for p in toc_pages
        ])

        print(f"   ğŸ“ ç›®å½•æ–‡æœ¬é•¿åº¦ï¼š{len(toc_text)} å­—ç¬¦")

        # æ­¥éª¤ 4ï¼šLLM æå–
        chapters = await self._llm_extract_from_toc(toc_text, document_id, user_id, db)

        return chapters

    def _find_toc_start_page(self, pages: List[Dict]) -> Optional[int]:
        """æ‰¾åˆ°ç›®å½•èµ·å§‹é¡µ"""

        # ç›®å½•æ ‡é¢˜æ¨¡å¼
        toc_title_patterns = [
            r'^ç›®å½•\s*$',  # "ç›®å½•"
            r'^ç›®\s*å½•\s*$',  # "ç›®ã€€å½•"ï¼ˆå¯èƒ½æœ‰å…¨è§’ç©ºæ ¼ï¼‰
            r'^ç›®\s+å½•$',  # "ç›®   å½•"
            r'^Contents\s*$',  # "Contents"
            r'^TABLE OF CONTENTS\s*$',  # "TABLE OF CONTENTS"
            r'^ç« èŠ‚ç›®å½•\s*$',  # "ç« èŠ‚ç›®å½•"
            r'^è¯¾\s*é¢˜\s*$',  # "è¯¾é¢˜"
        ]

        for page_data in pages:
            text = page_data.get('text', '')
            page_num = page_data.get('page_num')

            # æå–å‰ 500 å­—ç¬¦ï¼ˆé€šå¸¸ç›®å½•æ ‡é¢˜åœ¨å¼€å¤´ï¼‰
            header = text[:500].strip()

            for pattern in toc_title_patterns:
                if re.search(pattern, header, re.IGNORECASE | re.MULTILINE):
                    print(f"      â†’ ç¬¬ {page_num} é¡µåŒ¹é…ç›®å½•æ ‡é¢˜: {pattern}")
                    return page_num

        return None

    def _extract_continuous_toc_pages(
        self,
        pages: List[Dict],
        start_page: int
    ) -> List[Dict]:
        """ä»èµ·å§‹é¡µå¼€å§‹ï¼Œæå–è¿ç»­çš„ç›®å½•é¡µ"""

        # æ‰¾åˆ°èµ·å§‹é¡µçš„ç´¢å¼•
        start_index = None
        for i, page in enumerate(pages):
            if page['page_num'] == start_page:
                start_index = i
                break

        if start_index is None:
            return []

        # ä»èµ·å§‹é¡µå¼€å§‹ï¼Œè¿ç»­å–é¡µï¼Œç›´åˆ°ç›®å½•æ˜æ˜¾ç»“æŸ
        toc_pages = []
        consecutive_non_toc = 0  # è¿ç»­éç›®å½•é¡µè®¡æ•°

        for i in range(start_index, min(start_index + 20, len(pages))):
            page = pages[i]
            text = page['text']

            # æ£€æŸ¥è¿™é¡µæ˜¯å¦è¿˜åƒç›®å½•é¡µ
            if self._is_likely_toc_page(text):
                toc_pages.append(page)
                consecutive_non_toc = 0
            else:
                consecutive_non_toc += 1
                if consecutive_non_toc > 2:  # è¿ç»­ 2 é¡µä¸åƒç›®å½•ï¼Œå°±åœæ­¢
                    break

        return toc_pages

    def _is_likely_toc_page(self, text: str) -> bool:
        """åˆ¤æ–­è¿™é¡µæ˜¯å¦åƒç›®å½•é¡µ"""

        # å¿«é€Ÿæ£€æŸ¥ï¼šå¿…é¡»æœ‰ç« èŠ‚å…³é”®è¯
        chapter_indicators = [
            r'ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+ç« ',
            r'Chapter\s+\d+',
            r'[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ã€',
            r'\d+\.\d+',  # 1.1, 1.2
        ]

        has_chapter = any(re.search(p, text) for p in chapter_indicators)

        if not has_chapter:
            return False

        # è®¡ç®—ç›®å½•ç‰¹å¾åˆ†æ•°
        score = 0

        # é¡µç å¯†åº¦
        page_pattern = r'\d+\s*[é¡µpP]|P\.\s*\d+'
        page_count = len(re.findall(page_pattern, text))
        if page_count >= 3:
            score += 2

        # ç« èŠ‚ç¼–å·å¯†åº¦
        chapter_count = 0
        for pattern in chapter_indicators:
            chapter_count += len(re.findall(pattern, text))
        if chapter_count >= 3:
            score += 3

        # å°èŠ‚ç¼–å·
        subsection_count = len(re.findall(r'\d+\.\d+', text))
        if subsection_count >= 5:
            score += 1

        return score >= 3

    async def _extended_range_extraction(
        self,
        file_path: str,
        document_id: int,
        user_id: int,
        db: AsyncSession
    ) -> Optional[List[Dict[str, Any]]]:
        """ç­–ç•¥ 3ï¼šæ‰©å¤§èŒƒå›´é‡è¯•"""

        try:
            import fitz
            from app.core.ocr_engine import get_ocr_engine

            doc = fitz.open(file_path)
            total_pages = len(doc)
            doc.close()

            # æ‰«ææ›´å¤šé¡µé¢ï¼ˆå‰ 150 é¡µï¼‰
            scan_range = min(self.MAX_SCAN_PAGES, total_pages)

            print(f"   ğŸ“– æ‰©å¤§æ‰«æèŒƒå›´ï¼šå‰ {scan_range} é¡µ")

            # æ‰§è¡Œ OCR
            ocr_engine = get_ocr_engine()
            pages_to_ocr = list(range(1, scan_range + 1))

            print(f"   ğŸ”¬ æ­£åœ¨ OCR {len(pages_to_ocr)} é¡µ...")

            ocr_result = ocr_engine.process_pdf(
                pdf_path=file_path,
                pages=pages_to_ocr
            )

            if not ocr_result['success']:
                print(f"   âŒ OCR å¤±è´¥")
                return None

            # ä½¿ç”¨æ™ºèƒ½å®šä½ç­–ç•¥
            chapters = await self._locate_toc_pages_smart(
                ocr_result, file_path, document_id, user_id, db
            )

            return chapters

        except Exception as e:
            print(f"   âŒ æ‰©å¤§èŒƒå›´æå–å¤±è´¥: {e}")
            return None

    async def _heuristic_fallback(
        self,
        file_path: str,
        document_id: int,
        user_id: int,
        db: AsyncSession
    ) -> List[Dict[str, Any]]:
        """ç­–ç•¥ 4ï¼šå¯å‘å¼ Fallback"""

        print(f"   ğŸ”„ ä½¿ç”¨å¯å‘å¼æ–¹æ³•...")

        # ç®€å•çš„æ­£åˆ™æå–
        try:
            import fitz
            doc = fitz.open(file_path)

            # æå–å‰ 30 é¡µçš„æ–‡æœ¬
            all_text = ""
            for i in range(min(30, len(doc))):
                page = doc[i]
                text = page.get_text()
                if text.strip():
                    all_text += f"\n--- ç¬¬{i+1}é¡µ ---\n{text}"

            doc.close()

            # ä½¿ç”¨ LLM æå–
            chapters = await self._llm_extract_from_toc(all_text, document_id, user_id, db)

            if chapters:
                return chapters
            else:
                # æœ€åçš„ fallbackï¼šè¿”å›ä¸€ä¸ªé»˜è®¤ç« èŠ‚
                print(f"   âš ï¸  æ— æ³•æå–ç›®å½•ï¼Œåˆ›å»ºé»˜è®¤ç« èŠ‚")
                return [{
                    'chapter_number': 1,
                    'chapter_title': 'å…¨æ–‡',
                    'page_number': 1,
                    'subsections': []
                }]

        except Exception as e:
            print(f"   âŒ Fallback å¤±è´¥: {e}")
            return []

    def _format_bookmarks(self, toc: list) -> str:
        """æ ¼å¼åŒ–ä¹¦ç­¾ä¸ºæ–‡æœ¬"""

        toc_parts = []
        for level, title, page_num in toc:
            indent = "  " * (level - 1)
            toc_parts.append(f"{indent}{'â€¢' * level} {title} (ç¬¬{page_num}é¡µ)")

        return "\n".join(toc_parts)

    async def _llm_extract_from_toc(
        self,
        toc_text: str,
        document_id: int,
        user_id: int,
        db: AsyncSession
    ) -> Optional[List[Dict[str, Any]]]:
        """ä½¿ç”¨ LLM ä»ç›®å½•æ–‡æœ¬æå–ç« èŠ‚"""

        print(f"   ğŸ§  è°ƒç”¨ LLM æå–ç« èŠ‚...")
        print(f"   ğŸ“ æ–‡æœ¬é•¿åº¦ï¼š{len(toc_text)} å­—ç¬¦")

        try:
            import httpx

            prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•™æç›®å½•è¯†åˆ«ä¸“å®¶ã€‚è¯·ä»ä¸‹é¢çš„æ–‡æœ¬ä¸­æå–æ•™æçš„ç›®å½•ç»“æ„ã€‚

ã€å…³é”®è¦æ±‚ã€‘ï¼š
1. **å¿…é¡»æå–æ‰€æœ‰ç« èŠ‚**ï¼Œä¸è¦é—æ¼ä»»ä½•ç« èŠ‚
2. **å¿…é¡»æå–æ‰€æœ‰å°èŠ‚**ï¼ŒåŒ…æ‹¬å­å°èŠ‚
3. å¦‚æœç›®å½•å¾ˆé•¿ï¼ˆè¶…è¿‡10ç« ï¼‰ï¼Œä¹Ÿè¦å…¨éƒ¨æå–
4. æ³¨æ„ï¼šæœ‰äº›æ•™æå¯èƒ½æœ‰é™„å½•ã€å‚è€ƒæ–‡çŒ®ç­‰ï¼Œè¿™äº›ä¸ç®—åœ¨ä¸»è¦ç« èŠ‚å†…

ã€æ–‡æœ¬å†…å®¹ã€‘ï¼š
```
{toc_text[:8000]}
```

ã€è¿”å›æ ¼å¼ã€‘ï¼ˆä¸¥æ ¼æŒ‰ç…§ JSON æ ¼å¼ï¼‰ï¼š
{{
  "has_toc": true,
  "confidence": "high",
  "total_chapters": ç« èŠ‚æ€»æ•°,
  "chapters": [
    {{
      "chapter_number": 1,
      "chapter_title": "ç« èŠ‚æ ‡é¢˜",
      "page_number": é¡µç ,
      "subsections": [
        {{"subsection_number": "1.1", "subsection_title": "å°èŠ‚æ ‡é¢˜", "page_number": é¡µç }}
      ]
    }}
  ]
}}

ã€æ³¨æ„ã€‘ï¼š
- å¦‚æœç›®å½•è¶…è¿‡ 8000 å­—ç¬¦è¢«æˆªæ–­ï¼Œè¯·å‘Šè¯‰æˆ‘ï¼Œæˆ‘ä¼šæä¾›æ›´å¤šæ–‡æœ¬
- å¿…é¡»æå–å®Œæ•´ï¼Œä¸è¦å› ä¸ºç« èŠ‚å¤šå°±åœæ­¢
"""

            # è°ƒç”¨ LLM
            async with httpx.AsyncClient(timeout=60.0) as client:
                response = await client.post(
                    "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions",
                    headers={
                        "Authorization": f"Bearer {self.api_key}",
                        "Content-Type": "application/json"
                    },
                    json={
                        "model": self.model,
                        "messages": [
                            {"role": "system", "content": "ä½ æ˜¯ä¸“ä¸šçš„æ•™æç›®å½•è¯†åˆ«ä¸“å®¶ã€‚"},
                            {"role": "user", "content": prompt}
                        ],
                        "temperature": 0.1,  # é™ä½æ¸©åº¦ï¼Œæé«˜å‡†ç¡®æ€§
                        "max_tokens": 8000
                    }
                )

            if response.status_code != 200:
                print(f"   âŒ LLM è°ƒç”¨å¤±è´¥ï¼š{response.status_code}")
                return None

            result = response.json()
            content = result['choices'][0]['message']['content']

            # è§£æ JSON
            # æå– JSON éƒ¨åˆ†ï¼ˆå¯èƒ½åŒ…å«åœ¨ ```json ä¸­ï¼‰
            json_match = re.search(r'```json\s*([\s\S]*?)\s*```', content)
            if json_match:
                json_str = json_match.group(1)
            else:
                json_str = content

            data = json.loads(json_str)

            if not data.get('has_toc'):
                print(f"   âš ï¸  LLM è®¤ä¸ºæ²¡æœ‰ç›®å½•")
                return None

            chapters = data.get('chapters', [])

            print(f"   âœ… LLM æå–äº† {len(chapters)} ä¸ªç« èŠ‚")

            # åˆ›å»ºç« èŠ‚è®°å½•
            for chapter_info in chapters:
                await self._create_chapter_progress(
                    db, document_id, user_id, chapter_info
                )

            return chapters

        except json.JSONDecodeError as e:
            print(f"   âŒ JSON è§£æå¤±è´¥: {e}")
            print(f"   ğŸ“„ LLM å“åº”ï¼š{content[:500]}")
            return None
        except Exception as e:
            print(f"   âŒ LLM æå–å¤±è´¥: {e}")
            return None

    def _validate_chapter_count(self, chapters: List[Dict[str, Any]]) -> bool:
        """éªŒè¯ç« èŠ‚æ•°é‡æ˜¯å¦åˆç†"""

        if not chapters:
            return False

        count = len(chapters)

        # åˆç†èŒƒå›´ï¼š3-30 ç« 
        if count < 3:
            print(f"   âš ï¸  ç« èŠ‚æ•°é‡å¤ªå°‘ï¼š{count} ç« ")
            return False

        if count > 30:
            print(f"   âš ï¸  ç« èŠ‚æ•°é‡å¼‚å¸¸å¤šï¼š{count} ç« ï¼ˆå¯èƒ½æœ‰é‡å¤ï¼‰")
            # ä¸è¿”å› Falseï¼Œè®©ç”¨æˆ·å†³å®š

        print(f"   âœ… ç« èŠ‚æ•°é‡åˆç†ï¼š{count} ç« ")
        return True

    async def _create_chapter_progress(
        self,
        db: AsyncSession,
        document_id: int,
        user_id: int,
        chapter_info: Dict[str, Any]
    ):
        """åˆ›å»ºç« èŠ‚è¿›åº¦è®°å½•"""

        from app.models.document import Progress
        from sqlalchemy import select

        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        existing = await db.execute(
            select(Progress).where(
                Progress.document_id == document_id,
                Progress.chapter_number == chapter_info['chapter_number']
            )
        )
        if existing.scalar_one_or_none():
            return

        # åˆ›å»ºæ–°è®°å½•
        progress = Progress(
            document_id=document_id,
            user_id=user_id,
            chapter_number=chapter_info['chapter_number'],
            chapter_title=chapter_info['chapter_title'],
            completion_percentage=0.0,
            time_spent_minutes=0,
            is_locked=True  # é»˜è®¤é”å®š
        )

        db.add(progress)
        await db.commit()
