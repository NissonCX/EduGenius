"""
FastAPI endpoints for document upload and processing with MD5 deduplication.
"""
from fastapi import APIRouter, Depends, UploadFile, File, HTTPException, status
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import text
from typing import Optional
import tempfile
import os

from app.db.database import get_db, async_session_maker
from app.crud.document import (
    calculate_md5_hash,
    get_document_by_md5,
    create_document,
    get_or_create_user,
    update_document_status,
    get_user_progress_for_document,
    create_progress
)
from app.services.document_processor import process_uploaded_document, DocumentProcessor
from app.core.chroma import create_document_collection, add_document_chunks
from app.core.security import get_current_user
from app.core.logging_config import get_logger
from app.schemas.document import (
    DocumentUploadResponse,
    DocumentResponse,
    ChapterResponse,
    ProgressCreate
)
from app.models.document import User

logger = get_logger(__name__)

router = APIRouter(prefix="/api/documents", tags=["documents"])


# For demo: use a default user
DEFAULT_USER_EMAIL = "demo@edugenius.ai"
DEFAULT_USERNAME = "demo_user"


@router.post("/upload")
async def upload_document(
    file: UploadFile = File(...),
    title: Optional[str] = None,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """
    Upload document with MD5-based deduplication and RAG processing.

    å®Œæ•´æµç¨‹ï¼š
    1. è®¡ç®— MD5 å“ˆå¸Œ
    2. æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼ˆå»é‡ï¼‰
    3. è§£æ PDF/TXT
    4. è¯­ä¹‰åˆ‡åˆ†
    5. DashScope å‘é‡åŒ–
    6. å­˜å…¥ ChromaDB
    7. åˆ›å»ºæ•°æ®åº“è®°å½•

    æ³¨æ„ï¼šå¤§æ–‡ä»¶å¤„ç†å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…
    """
    import asyncio
    from app.core.config import settings

    # æ–‡ä»¶å¤§å°é™åˆ¶ï¼ˆ50MBï¼‰
    MAX_FILE_SIZE = 50 * 1024 * 1024

    # è¯»å–æ–‡ä»¶å†…å®¹
    content = await file.read()

    # æ£€æŸ¥æ–‡ä»¶å¤§å°
    if len(content) > MAX_FILE_SIZE:
        raise HTTPException(
            status_code=status.HTTP_413_REQUEST_ENTITY_TOO_LARGE,
            detail=f"æ–‡ä»¶è¿‡å¤§ï¼Œæœ€å¤§æ”¯æŒ {MAX_FILE_SIZE // (1024*1024)}MB"
        )

    # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
    tmp_file_path = None
    permanent_file_path = None
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(file.filename)[1]) as tmp_file:
            tmp_file.write(content)
            tmp_file.flush()  # ğŸ”§ ç¡®ä¿å†…å®¹å†™å…¥ç£ç›˜
            tmp_file_path = tmp_file.name

        print(f"ğŸ“„ å¼€å§‹å¤„ç†æ–‡æ¡£: {file.filename} ({len(content)} bytes)")

        # è®¡ç®—æ–‡æ¡£å¤„ç†å™¨
        processor = DocumentProcessor()
        md5_hash = processor.calculate_md5(tmp_file_path)
        print(f"ğŸ” MD5: {md5_hash}")

        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        existing_document = await get_document_by_md5(db, md5_hash)

        if existing_document:
            # æ–‡æ¡£å†…å®¹å·²å­˜åœ¨ï¼Œä½†ä¸ºå½“å‰ç”¨æˆ·åˆ›å»ºæ–°çš„æ–‡æ¡£è®°å½•
            # è¿™æ ·å¯ä»¥å¤ç”¨ ChromaDB å‘é‡æ•°æ®ï¼Œä½†æ¯ä¸ªç”¨æˆ·æœ‰ç‹¬ç«‹çš„å­¦ä¹ è¿›åº¦
            
            # æ£€æŸ¥å½“å‰ç”¨æˆ·æ˜¯å¦å·²ç»æœ‰è¿™ä¸ªæ–‡æ¡£
            from sqlalchemy import select, and_
            from app.models.document import Document as DocumentModel
            
            user_doc_result = await db.execute(
                select(DocumentModel).where(
                    and_(
                        DocumentModel.md5_hash == md5_hash,
                        DocumentModel.uploaded_by == current_user.id
                    )
                )
            )
            user_existing_doc = user_doc_result.scalar_one_or_none()
            
            if user_existing_doc:
                # ç”¨æˆ·å·²ç»ä¸Šä¼ è¿‡è¿™ä¸ªæ–‡æ¡£
                return DocumentUploadResponse(
                    message="âœ¨ æ‚¨å·²ä¸Šä¼ è¿‡æ­¤æ–‡æ¡£",
                    is_duplicate=True,
                    document_id=user_existing_doc.id,
                    md5_hash=md5_hash,
                    processing_status=user_existing_doc.processing_status
                )
            
            # ä¸ºå½“å‰ç”¨æˆ·åˆ›å»ºæ–°çš„æ–‡æ¡£è®°å½•ï¼ˆå¤ç”¨å‘é‡æ•°æ®ï¼‰
            from app.schemas.document import DocumentCreate
            document_data = DocumentCreate(
                filename=file.filename,
                file_type=file.filename.split(".")[-1].lower(),
                file_size=len(content),
                md5_hash=md5_hash
            )
            
            new_document = await create_document(db, document_data, current_user.id)
            
            # æ›´æ–°æ–‡æ¡£çŠ¶æ€
            await update_document_status(
                db,
                new_document.id,
                status="completed",
                total_pages=existing_document.total_pages,
                total_chapters=0,
                title=title or file.filename
            )
            
            # ä¸ºæ–°ç”¨æˆ·åˆ›å»ºç« èŠ‚ï¼ˆä»åŸå§‹æ–‡ä»¶æå–ç›®å½•ï¼‰
            try:
                from app.services.chapter_divider_enhanced import EnhancedChapterDivider
                from app.services.document_processor_v2 import EnhancedDocumentProcessor
                from app.core.chroma import get_document_collection

                divider = EnhancedChapterDivider()
                toc_text = ""

                # å°è¯•ä»åŸå§‹ PDF æ–‡ä»¶æå–ç›®å½•
                if existing_document.file_type == "pdf":
                    try:
                        enhanced_processor = EnhancedDocumentProcessor()
                        # ä½¿ç”¨åŸå§‹æ–‡ä»¶è·¯å¾„
                        original_file = f"uploads/{current_user.id}_{existing_document.filename}"
                        if os.path.exists(original_file):
                            # ğŸ”§ FIX: å¢åŠ åˆ°15é¡µï¼Œç¡®ä¿åŒ…å«å®Œæ•´ç›®å½•
                            _, toc_text = enhanced_processor.extract_toc_pages(original_file, max_toc_pages=15)
                            print(f"ğŸ“š ä»ç°æœ‰ PDF æå–äº†ç›®å½•: {len(toc_text)} å­—ç¬¦")
                    except Exception as e:
                        print(f"âš ï¸  ä» PDF æå–ç›®å½•å¤±è´¥: {e}")

                # å¦‚æœæ²¡æœ‰ TOCï¼Œå°è¯•ä» ChromaDB è·å–å‰å‡ ä¸ª chunks
                if not toc_text:
                    collection = get_document_collection(md5_hash)
                    if collection and collection.count() > 0:
                        results = collection.get()
                        if results and results['documents']:
                            # åªä½¿ç”¨å‰å‡ ä¸ª chunks ä½œä¸º TOC çš„ fallback
                            toc_text = "\n\n".join(results['documents'][:3])

                if toc_text:
                    chapters = await divider.divide_document_into_chapters(
                        document_id=new_document.id,
                        user_id=current_user.id,
                        document_text=toc_text,
                        db=db
                    )

                    print(f"âœ… ä¸ºæ–°ç”¨æˆ·åˆ›å»ºäº† {len(chapters)} ä¸ªç« èŠ‚")
            except Exception as e:
                print(f"âš ï¸  ç« èŠ‚åˆ’åˆ†å¤±è´¥: {str(e)}")
                import traceback
                traceback.print_exc()
            
            return DocumentUploadResponse(
                message=f"âœ¨ æ–‡æ¡£å·²å­˜åœ¨ï¼Œå·²ä¸ºæ‚¨åˆ›å»ºå­¦ä¹ è®°å½•",
                is_duplicate=True,
                document_id=new_document.id,
                md5_hash=md5_hash,
                processing_status="completed"
            )

        # å¤„ç†æ–°æ–‡æ¡£
        file_type = file.filename.split(".")[-1].lower()
        if file_type not in ["pdf", "txt"]:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_type}ã€‚æ”¯æŒçš„æ ¼å¼: pdf, txt"
            )

        # åˆ›å»ºæ•°æ®åº“è®°å½•ï¼ˆå¿…é¡»åœ¨å¤„ç†ä¹‹å‰åˆ›å»ºï¼Œä»¥ä¾¿è·å–document_idï¼‰
        from app.schemas.document import DocumentCreate
        document_data = DocumentCreate(
            filename=file.filename,
            file_type=file_type,
            file_size=len(content),
            md5_hash=md5_hash
        )

        new_document = await create_document(db, document_data, current_user.id)

        # ğŸ”§ åˆ›å»ºæ°¸ä¹…æ–‡ä»¶ç›®å½•å¹¶ç§»åŠ¨æ–‡ä»¶
        os.makedirs("uploads", exist_ok=True)
        permanent_file_path = f"uploads/{current_user.id}_{new_document.id}_{file.filename}"
        import shutil
        shutil.move(tmp_file_path, permanent_file_path)
        print(f"ğŸ’¾ æ–‡ä»¶å·²ä¿å­˜åˆ°: {permanent_file_path}")

        print(f"ğŸ“– å¼€å§‹è§£æ {file_type} æ–‡æ¡£...")

        # ğŸ” æ™ºèƒ½æ··åˆå¤„ç†ï¼šä½¿ç”¨ HybridDocumentProcessor
        if file_type == "pdf":
            logger.info("ğŸ¯ æ£€æµ‹åˆ°PDFæ–‡ä»¶ï¼Œå°†ä½¿ç”¨HybridDocumentProcessorå¤„ç†")
            try:
                from app.services.hybrid_document_processor import HybridDocumentProcessor
                from app.utils.pdf_validator import validate_pdf_before_upload

                logger.info("âœ… HybridDocumentProcessorå¯¼å…¥æˆåŠŸ")
                print(f"\n{'='*60}")
                print(f"ğŸ”¬ æ™ºèƒ½æ··åˆå¤„ç†æ¨¡å¼")
                print(f"{'='*60}\n")

                # é¢„æ£€æµ‹
                validation = validate_pdf_before_upload(permanent_file_path)

                print(f"ğŸ“‹ PDF é¢„æ£€æŸ¥ç»“æœ:")
                print(f"   æ€»é¡µæ•°: {validation['total_pages']}")
                print(f"   æ–‡æœ¬é¡µ: {validation['text_pages']}")
                print(f"   æ–‡æœ¬å æ¯”: {validation['text_ratio']:.1%}")
                print(f"   æ˜¯å¦æ‰«æç‰ˆ: {'âš ï¸  æ˜¯' if validation['is_scan'] else 'âœ… å¦'}")
                print(f"{'='*60}\n")

                # å¦‚æœæ˜¯æ‰«æç‰ˆï¼Œç»™å‡ºæç¤ºä½†ç»§ç»­å¤„ç†ï¼ˆä¸å†æ‹’ç»ï¼‰
                if validation['is_scan']:
                    print(f"ğŸ’¡ æ£€æµ‹åˆ°æ‰«æç‰ˆPDFï¼Œå°†ä½¿ç”¨ PaddleOCR è¿›è¡Œæ–‡å­—è¯†åˆ«")
                    print(f"   é¢„è®¡å¤„ç†æ—¶é—´: {validation['total_pages'] * 2}-{validation['total_pages'] * 5} ç§’\n")

                # ä½¿ç”¨æ··åˆå¤„ç†å™¨å¤„ç†æ–‡æ¡£
                processor = HybridDocumentProcessor()

                # æ›´æ–°çŠ¶æ€ä¸ºå¤„ç†ä¸­
                await db.execute(
                    text("UPDATE documents SET processing_status = :status WHERE id = :id"),
                    {"status": "pending", "id": new_document.id}
                )
                await db.commit()

                # æ£€æŸ¥ OCR å¹¶å‘é™åˆ¶
                if validation['is_scan']:
                    from app.core.ocr_semaphore import ocr_semaphore

                    task_id = f"doc_{new_document.id}"
                    acquired = await ocr_semaphore.acquire(task_id)

                    if not acquired:
                        # æ§½ä½å·²æ»¡ï¼Œæ’é˜Ÿå¤„ç†
                        await db.execute(
                            text("UPDATE documents SET processing_status = :status WHERE id = :id"),
                            {"status": "queued", "id": new_document.id}
                        )
                        await db.commit()

                        return DocumentUploadResponse(
                            message="â³ æœåŠ¡å™¨ç¹å¿™ï¼Œæ‚¨çš„æ–‡æ¡£å·²åŠ å…¥é˜Ÿåˆ—ï¼Œè¯·ç¨ååˆ·æ–°é¡µé¢æŸ¥çœ‹è¿›åº¦",
                            is_duplicate=False,
                            document_id=new_document.id,
                            md5_hash=md5_hash,
                            processing_status="queued"
                        )

                    logger.info(f"ğŸ” OCR ä»»åŠ¡ {task_id} è·å¾—å¤„ç†æƒé™")

                # å¼‚æ­¥å¤„ç†ï¼ˆä½¿ç”¨ asyncio.create_taskï¼‰
                async def process_document_async():
                    # åœ¨å¼‚æ­¥ä»»åŠ¡ä¸­åˆ›å»ºæ–°çš„æ•°æ®åº“ session
                    async with async_session_maker() as async_db:
                        try:
                            result = await processor.process_document(
                                file_path=permanent_file_path,
                                document_id=new_document.id,
                                user_id=current_user.id,
                                title=title or file.filename,
                                db=async_db
                            )

                            logger.info(
                                f"âœ… æ–‡æ¡£ {new_document.id} å¤„ç†å®Œæˆ: "
                                f"è·¯å¾„={result.get('path')}, "
                                f"è€—æ—¶={result.get('processing_time', 0):.1f}ç§’, "
                                f"OCRç½®ä¿¡åº¦={result.get('ocr_confidence', 0):.1%}"
                            )

                        except Exception as e:
                            logger.error(f"âŒ æ–‡æ¡£ {new_document.id} å¤„ç†å¤±è´¥: {e}", exc_info=True)

                            # æ›´æ–°çŠ¶æ€ä¸ºå¤±è´¥
                            await async_db.execute(
                                text("UPDATE documents SET processing_status = :status WHERE id = :id"),
                                {"status": "failed", "id": new_document.id}
                            )
                            await async_db.commit()

                # å¯åŠ¨å¼‚æ­¥å¤„ç†
                asyncio.create_task(process_document_async())

                # ç«‹å³è¿”å›ï¼Œè®©å‰ç«¯å¯ä»¥è½®è¯¢è¿›åº¦
                return DocumentUploadResponse(
                    message=f"âœ… æ–‡æ¡£å·²ä¸Šä¼ ï¼Œæ­£åœ¨{'OCRè¯†åˆ«' if validation['is_scan'] else 'å¤„ç†'}ä¸­...",
                    is_duplicate=False,
                    document_id=new_document.id,
                    md5_hash=md5_hash,
                    processing_status="pending" if validation['is_scan'] else "processing"
                )

            except HTTPException:
                raise  # é‡æ–°æŠ›å‡º HTTPException
            except Exception as e:
                # PDFå¤„ç†å¤±è´¥ï¼Œè®°å½•é”™è¯¯å¹¶è¿”å›å¤±è´¥çŠ¶æ€
                logger.error(f"âŒ PDF å¤„ç†å¤±è´¥: {e}", exc_info=True)

                # æ›´æ–°çŠ¶æ€ä¸ºå¤±è´¥
                await db.execute(
                    text("UPDATE documents SET processing_status = :status WHERE id = :id"),
                    {"status": "failed", "id": new_document.id}
                )
                await db.commit()

                raise HTTPException(
                    status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,
                    detail=f"æ–‡æ¡£å¤„ç†å¤±è´¥: {str(e)}"
                )

        # TXTæ–‡ä»¶å¤„ç†ï¼šè§£ææ–‡æ¡£ã€åˆ‡åˆ†ã€å‘é‡åŒ–ï¼ˆæ·»åŠ è¶…æ—¶ä¿æŠ¤ï¼‰
        try:
            result = await asyncio.wait_for(
                process_uploaded_document(
                    file_path=permanent_file_path,
                    title=title or file.filename,
                    user_email=current_user.email
                ),
                timeout=300.0  # 5åˆ†é’Ÿè¶…æ—¶
            )
            print(f"âœ… æ–‡æ¡£è§£æå®Œæˆ: {len(result.get('chunks', []))} ä¸ª chunks")
        except asyncio.TimeoutError:
            raise HTTPException(
                status_code=status.HTTP_408_REQUEST_TIMEOUT,
                detail="æ–‡æ¡£å¤„ç†è¶…æ—¶ï¼ˆè¶…è¿‡5åˆ†é’Ÿï¼‰ï¼Œè¯·å°è¯•ä¸Šä¼ è¾ƒå°çš„æ–‡ä»¶"
            )

        # ğŸ¯ å¦‚æœæ˜¯ PDFï¼Œä½¿ç”¨æ™ºèƒ½è§£æå™¨æå–ç›®å½•ï¼ˆä¹¦ç­¾ä¼˜å…ˆ + å¯å‘å¼æ‰«æï¼‰
        toc_text = ""
        if file_type == "pdf":
            try:
                from app.core.textbook_parser import TextbookParser
                parser = TextbookParser()

                parse_result = await parser.parse_textbook(permanent_file_path, db)
                toc_text = parse_result['toc_text']

                source = parse_result['source']  # 'bookmark' or 'scan'
                pages = parse_result['pages']
                need_ai = parse_result.get('need_ai_guess', False)

                print(f"ğŸ“š æ™ºèƒ½è§£æå®Œæˆ:")
                print(f"   æ¥æº: {source}")
                print(f"   é¡µç : {pages}")
                print(f"   æ–‡æœ¬é•¿åº¦: {len(toc_text)} å­—ç¬¦")
                if need_ai:
                    print(f"   âš ï¸  éœ€è¦AIè¾…åŠ©è¯†åˆ«")
            except Exception as e:
                logger.warning(f"âš ï¸  æ™ºèƒ½è§£æå¤±è´¥: {e}ï¼Œä½¿ç”¨fallback")
                toc_text = ""

        # åˆ›å»º ChromaDB collectionï¼ˆä»¥ MD5 å‘½åï¼‰
        create_document_collection(md5_hash)

        # æ·»åŠ  chunks åˆ° ChromaDB
        chunks = result['chunks']
        embeddings = result['embeddings']

        # å‡†å¤‡ metadata
        chunk_metadata = []
        for chunk in chunks:
            meta = chunk.metadata.copy()
            chunk_metadata.append(meta)

        # æå–æ–‡æœ¬å†…å®¹
        chunk_texts = [chunk.page_content for chunk in chunks]

        # å­˜å…¥ ChromaDB
        add_document_chunks(
            md5_hash=md5_hash,
            chunks=chunk_texts,
            embeddings=embeddings,
            metadata=chunk_metadata
        )

        # æ›´æ–°æ–‡æ¡£çŠ¶æ€
        await update_document_status(
            db,
            new_document.id,
            status="completed",
            total_pages=result['stats'].get('total_pages', 0),
            total_chapters=0,  # ç¨åç”±ç« èŠ‚åˆ’åˆ†æœåŠ¡æ›´æ–°
            title=title or file.filename
        )

        # ğŸ¯ æ ¸å¿ƒï¼šè‡ªåŠ¨åˆ’åˆ†ç« èŠ‚ï¼ˆä½¿ç”¨å¢å¼ºç‰ˆæœåŠ¡ï¼‰
        try:
            # ä½¿ç”¨å¢å¼ºç‰ˆç« èŠ‚åˆ’åˆ†æœåŠ¡
            from app.services.chapter_divider_enhanced import EnhancedChapterDivider

            divider = EnhancedChapterDivider()

            # ä½¿ç”¨å¢å¼ºç‰ˆå¤„ç†å™¨æå–çš„ç›®å½•æ–‡æœ¬
            # å¦‚æœ toc_text ä¸ºç©ºï¼ˆæ¯”å¦‚ txt æ–‡ä»¶ï¼‰ï¼Œä½¿ç”¨å¸¸è§„æ–‡æœ¬
            if not toc_text:
                # å¯¹äºé PDF æˆ–æå–å¤±è´¥çš„æƒ…å†µï¼Œä½¿ç”¨å‰å‡ ä¸ª chunks
                toc_text = "\n\n".join([c.page_content for c in chunks[:3]])

            if toc_text:
                print(f"ğŸ“š å‘é€ç›®å½•æ–‡æœ¬ç»™ LLMï¼Œé•¿åº¦: {len(toc_text)} å­—ç¬¦")

                chapters = await divider.divide_document_into_chapters(
                    document_id=new_document.id,
                    user_id=current_user.id,
                    document_text=toc_text,  # åªå‘é€ç›®å½•æ–‡æœ¬
                    db=db
                )

                print(f"âœ… æ–‡æ¡£å¤„ç†å®Œæˆï¼Œå…±åˆ’åˆ† {len(chapters)} ä¸ªç« èŠ‚")

                # æ›´æ–°æ–‡æ¡£çš„ç« èŠ‚æ•°
                await update_document_status(
                    db,
                    new_document.id,
                    status="completed",
                    total_chapters=len(chapters)
                )
            else:
                print("âš ï¸ æœªèƒ½æå–åˆ°ç›®å½•æ–‡æœ¬")
                # åˆ›å»ºé»˜è®¤ç« èŠ‚
                await create_progress(
                    db,
                    ProgressCreate(
                        user_id=current_user.id,
                        document_id=new_document.id,
                        chapter_number=1,
                        chapter_title=title or file.filename,
                        cognitive_level_assigned=current_user.cognitive_level
                    )
                )
        except Exception as e:
            print(f"âš ï¸  ç« èŠ‚åˆ’åˆ†å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            # å³ä½¿ç« èŠ‚åˆ’åˆ†å¤±è´¥ï¼Œä¹Ÿåˆ›å»ºä¸€ä¸ªé»˜è®¤ç« èŠ‚
            await create_progress(
                db,
                ProgressCreate(
                    user_id=current_user.id,
                    document_id=new_document.id,
                    chapter_number=1,
                    chapter_title=title or file.filename,
                    cognitive_level_assigned=current_user.cognitive_level
                )
            )

        return DocumentUploadResponse(
            message=f"âœ… æ–‡æ¡£ä¸Šä¼ æˆåŠŸï¼š{file.filename}",
            is_duplicate=False,
            document_id=new_document.id,
            md5_hash=md5_hash,
            processing_status="completed"
        )

    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"æ–‡æ¡£å¤„ç†å¤±è´¥: {str(e)}"
        )

    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼ˆåªåˆ é™¤ä¸´æ—¶æ–‡ä»¶ï¼Œä¸åˆ é™¤æ°¸ä¹…æ–‡ä»¶ï¼‰
        if tmp_file_path and os.path.exists(tmp_file_path):
            try:
                os.remove(tmp_file_path)
            except Exception as e:
                # è®°å½•é”™è¯¯ä½†ä¸æŠ›å‡ºå¼‚å¸¸
                print(f"âš ï¸  æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")


@router.get("/health")
async def health_check():
    """Health check endpoint."""
    return {"status": "healthy", "service": "EduGenius API"}


@router.get("/list")
async def list_documents(
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """
    è·å–å½“å‰ç”¨æˆ·ä¸Šä¼ çš„æ‰€æœ‰æ–‡æ¡£åˆ—è¡¨
    """
    from sqlalchemy import select
    from app.models.document import Document
    
    # æŸ¥è¯¢ç”¨æˆ·çš„æ‰€æœ‰æ–‡æ¡£
    result = await db.execute(
        select(Document).where(
            Document.uploaded_by == current_user.id
        ).order_by(Document.uploaded_at.desc())
    )
    documents = result.scalars().all()
    
    # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
    document_list = []
    for doc in documents:
        document_list.append({
            "id": doc.id,
            "filename": doc.filename,
            "title": doc.title or doc.filename,
            "file_type": doc.file_type,
            "file_size": doc.file_size,
            "total_pages": doc.total_pages,
            "total_chapters": doc.total_chapters,
            "processing_status": doc.processing_status,
            "uploaded_at": doc.uploaded_at.isoformat() if doc.uploaded_at else None,
            "md5_hash": doc.md5_hash
        })
    
    return {
        "documents": document_list,
        "total": len(document_list)
    }


@router.get("/{document_id}", response_model=DocumentResponse)
async def get_document(
    document_id: int,
    db: AsyncSession = Depends(get_db)
):
    """
    Get document details by ID.
    """
    document = await get_document_by_md5(db, str(document_id))
    if not document:
        # Try by ID
        from app.crud.document import get_document_by_id
        document = await get_document_by_id(db, document_id)

    if not document:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="æ–‡æ¡£ä¸å­˜åœ¨"
        )

    return document


@router.get("/{document_id}/chapters")
async def get_document_chapters(
    document_id: int,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """
    Get chapter list with progress and lock status for a document.

    è§£é”è§„åˆ™ï¼š
    - ç¬¬ä¸€ç« é»˜è®¤è§£é”
    - åç»­ç« èŠ‚éœ€è¦æ»¡è¶³å‰ç½®æ¡ä»¶ï¼š
      1. å‰ä¸€ç« å®Œæˆåº¦ >= 70%
      2. å‰ä¸€ç« æµ‹è¯•åˆ†æ•° >= 60%ï¼ˆå¦‚æœæœ‰æµ‹è¯•è®°å½•ï¼‰
      3. å‰ä¸€ç« å­¦ä¹ æ—¶é—´ >= 10 åˆ†é’Ÿ
    """
    from sqlalchemy import select
    from app.models.document import Document, Progress

    # éªŒè¯æ–‡æ¡£å­˜åœ¨
    doc_result = await db.execute(select(Document).where(Document.id == document_id))
    document = doc_result.scalar_one_or_none()
    if not document:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="æ–‡æ¡£ä¸å­˜åœ¨"
        )

    # è·å–æ‰€æœ‰è¿›åº¦è®°å½•
    progress_result = await db.execute(
        select(Progress).where(
            Progress.user_id == current_user.id,
            Progress.document_id == document_id
        ).order_by(Progress.chapter_number)
    )
    all_progress = progress_result.scalars().all()

    # è·å–æ‰€æœ‰å°èŠ‚è®°å½•ï¼ˆä½¿ç”¨åŸç”ŸSQLï¼Œé¿å…ORMé—®é¢˜ï¼‰
    from collections import defaultdict
    from sqlalchemy import text
    subsections_by_chapter = defaultdict(list)

    try:
        subsection_query = text("""
            SELECT chapter_number, subsection_number, subsection_title,
                   page_number, completion_percentage, time_spent_minutes
            FROM subsections
            WHERE user_id = :user_id AND document_id = :document_id
            ORDER BY chapter_number, subsection_number
        """)

        result = await db.execute(
            subsection_query,
            {"user_id": current_user.id, "document_id": document_id}
        )

        rows = result.fetchall()
        for row in rows:
            subsections_by_chapter[row[0]].append({
                "subsection_number": row[1],
                "subsection_title": row[2],
                "page_number": row[3],
                "completion_percentage": row[4],
                "time_spent_minutes": row[5]
            })
    except Exception as e:
        print(f"âš ï¸  æ— æ³•åŠ è½½å°èŠ‚æ•°æ®: {e}")
        # ç»§ç»­æ‰§è¡Œï¼Œåªæ˜¯ä¸åŒ…å«å°èŠ‚æ•°æ®

    # è§£é”é˜ˆå€¼é…ç½®
    UNLOCK_CONFIG = {
        "completion_threshold": 0.7,  # 70% å®Œæˆåº¦
        "quiz_score_threshold": 0.6,  # 60% æµ‹è¯•åˆ†æ•°
        "min_time_minutes": 10  # æœ€å°‘10åˆ†é’Ÿå­¦ä¹ æ—¶é—´
    }

    chapters = []

    for progress in all_progress:
        # åˆ¤æ–­ç« èŠ‚çŠ¶æ€
        is_locked = False
        lock_reason = None

        if progress.chapter_number > 1:
            # æŸ¥æ‰¾å‰ä¸€ç« çš„è¿›åº¦
            prev_progress = next(
                (p for p in all_progress if p.chapter_number == progress.chapter_number - 1),
                None
            )

            if prev_progress:
                # æ£€æŸ¥è§£é”æ¡ä»¶
                conditions_met = []
                conditions_not_met = []

                # æ£€æŸ¥å®Œæˆåº¦
                if prev_progress.completion_percentage >= UNLOCK_CONFIG["completion_threshold"] * 100:
                    conditions_met.append(f"å®Œæˆåº¦ {prev_progress.completion_percentage:.0f}%")
                else:
                    conditions_not_met.append(
                        f"å‰ä¸€ç« å®Œæˆåº¦éœ€è¾¾åˆ° {UNLOCK_CONFIG['completion_threshold'] * 100:.0f}%ï¼ˆå½“å‰ {prev_progress.completion_percentage:.0f}%ï¼‰"
                    )

                # æ£€æŸ¥å­¦ä¹ æ—¶é—´
                if prev_progress.time_spent_minutes >= UNLOCK_CONFIG["min_time_minutes"]:
                    conditions_met.append(f"å­¦ä¹ æ—¶é—´ {prev_progress.time_spent_minutes} åˆ†é’Ÿ")
                else:
                    conditions_not_met.append(
                        f"å‰ä¸€ç« å­¦ä¹ æ—¶é—´éœ€è¾¾åˆ° {UNLOCK_CONFIG['min_time_minutes']} åˆ†é’Ÿï¼ˆå½“å‰ {prev_progress.time_spent_minutes} åˆ†é’Ÿï¼‰"
                    )

                # æ£€æŸ¥æµ‹è¯•åˆ†æ•°ï¼ˆå¦‚æœæœ‰æµ‹è¯•è®°å½•ï¼‰
                if prev_progress.quiz_attempts > 0:
                    if prev_progress.quiz_success_rate >= UNLOCK_CONFIG["quiz_score_threshold"]:
                        conditions_met.append(f"æµ‹è¯•åˆ†æ•° {prev_progress.quiz_success_rate * 100:.0f}%")
                    else:
                        conditions_not_met.append(
                            f"å‰ä¸€ç« æµ‹è¯•åˆ†æ•°éœ€è¾¾åˆ° {UNLOCK_CONFIG['quiz_score_threshold'] * 100:.0f}%ï¼ˆå½“å‰ {prev_progress.quiz_success_rate * 100:.0f}%ï¼‰"
                        )

                # å¦‚æœæ‰€æœ‰æ¡ä»¶éƒ½æ»¡è¶³ï¼Œåˆ™è§£é”
                is_locked = len(conditions_not_met) > 0

                if is_locked:
                    lock_reason = f"éœ€å®Œæˆå‰ä¸€ç« ï¼š{'; '.join(conditions_not_met)}"
            else:
                # æ²¡æœ‰å‰ä¸€ç« è®°å½•ï¼Œé”å®š
                is_locked = True
                lock_reason = "éœ€å…ˆå®Œæˆå‰ä¸€ç« "

        # å¦‚æœçŠ¶æ€ä¸º lockedï¼Œå¼ºåˆ¶é”å®š
        if progress.status == "locked":
            is_locked = True
            lock_reason = "æ­¤ç« èŠ‚å·²è¢«é”å®š"

        # ç¡®å®šçŠ¶æ€å›¾æ ‡
        if is_locked:
            status_icon = "ğŸ”’"
            status_text = "æœªè§£é”"
        elif progress.status == "completed":
            status_icon = "âœ…"
            status_text = "å·²å®Œæˆ"
        elif progress.status == "in_progress":
            status_icon = "ğŸ”“"
            status_text = "å­¦ä¹ ä¸­"
        else:
            status_icon = "ğŸ”“"
            status_text = "æœªå¼€å§‹"

        chapters.append({
            "chapter_number": progress.chapter_number,
            "chapter_title": progress.chapter_title or f"ç¬¬ {progress.chapter_number} ç« ",
            "status": progress.status,
            "completion_percentage": progress.completion_percentage,
            "is_locked": is_locked,
            "lock_reason": lock_reason,
            "status_icon": status_icon,
            "status_text": status_text,
            "time_spent_minutes": progress.time_spent_minutes,
            "quiz_attempts": progress.quiz_attempts,
            "quiz_success_rate": progress.quiz_success_rate,
            "subsections": subsections_by_chapter.get(progress.chapter_number, []),
            "subsection_count": len(subsections_by_chapter.get(progress.chapter_number, []))
        })

    return {
        "document_id": document_id,
        "document_title": document.title or document.filename,
        "total_chapters": len(chapters),
        "chapters": chapters
    }


@router.post("/{document_id}/redivide-chapters")
async def redivide_chapters(
    document_id: int,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """
    é‡æ–°åˆ’åˆ†æ–‡æ¡£ç« èŠ‚
    ä½¿ç”¨ LLM é‡æ–°åˆ†ææ–‡æ¡£å¹¶åˆ’åˆ†ç« èŠ‚
    """
    from sqlalchemy import select, delete
    from app.models.document import Document, Progress
    from app.services.chapter_divider import ChapterDivider
    from app.services.document_processor import DocumentProcessor

    # éªŒè¯æ–‡æ¡£å­˜åœ¨
    doc_result = await db.execute(select(Document).where(Document.id == document_id))
    document = doc_result.scalar_one_or_none()

    if not document:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="æ–‡æ¡£ä¸å­˜åœ¨"
        )

    # éªŒè¯æ–‡æ¡£æ‰€æœ‰æƒ
    if document.uploaded_by != current_user.id:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="æ— æƒé™æ“ä½œæ­¤æ–‡æ¡£"
        )

    try:
        # åˆ é™¤æ—§çš„ç« èŠ‚è¿›åº¦è®°å½•
        await db.execute(
            delete(Progress).where(
                Progress.user_id == current_user.id,
                Progress.document_id == document_id
            )
        )
        await db.commit()

        # é‡æ–°è§£ææ–‡æ¡£
        processor = DocumentProcessor()
        result = await processor.process_document(
            file_path=None,  # è¿™é‡Œéœ€è¦ä¿®æ”¹ï¼Œåº”è¯¥ä½¿ç”¨å­˜å‚¨çš„æ–‡ä»¶
            metadata={'title': document.title}
        )

        # è·å–æ–‡æ¡£æ–‡æœ¬
        document_text = result['texts'][0] if result['texts'] else ""

        if not document_text:
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail="æ— æ³•æå–æ–‡æ¡£å†…å®¹"
            )

        # é‡æ–°åˆ’åˆ†ç« èŠ‚
        divider = ChapterDivider()
        chapters = await divider.divide_document_into_chapters(
            document_id=document_id,
            user_id=current_user.id,
            document_text=document_text,
            db=db
        )

        return {
            "message": f"âœ… ç« èŠ‚é‡æ–°åˆ’åˆ†æˆåŠŸï¼Œå…± {len(chapters)} ä¸ªç« èŠ‚",
            "document_id": document_id,
            "total_chapters": len(chapters),
            "chapters": chapters
        }

    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_SERVER_ERROR,
            detail=f"ç« èŠ‚åˆ’åˆ†å¤±è´¥: {str(e)}"
        )


@router.get("/{document_id}/chapters/{chapter_number}/subsections")
async def get_chapter_subsections(
    document_id: int,
    chapter_number: int,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """
    è·å–ç« èŠ‚çš„æ‰€æœ‰å°èŠ‚
    """
    from sqlalchemy import select
    from app.models.subsection import Subsection
    from app.models.document import Progress
    
    # éªŒè¯ç« èŠ‚å­˜åœ¨
    progress_result = await db.execute(
        select(Progress).where(
            Progress.user_id == current_user.id,
            Progress.document_id == document_id,
            Progress.chapter_number == chapter_number
        )
    )
    progress = progress_result.scalar_one_or_none()
    
    if not progress:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="ç« èŠ‚ä¸å­˜åœ¨"
        )
    
    # è·å–æ‰€æœ‰å°èŠ‚
    subsections_result = await db.execute(
        select(Subsection).where(
            Subsection.document_id == document_id,
            Subsection.chapter_number == chapter_number
        ).order_by(Subsection.subsection_number)
    )
    subsections = subsections_result.scalars().all()
    
    # ä¸€æ¬¡æ€§è·å–æ‰€æœ‰å°èŠ‚çš„è¿›åº¦ï¼ˆä¼˜åŒ– N+1 æŸ¥è¯¢ï¼‰
    subsection_numbers = [s.subsection_number for s in subsections]
    if subsection_numbers:
        progress_result = await db.execute(
            select(Progress).where(
                Progress.user_id == current_user.id,
                Progress.document_id == document_id,
                Progress.chapter_number == chapter_number,
                Progress.subsection_number.in_(subsection_numbers)
            )
        )
        progress_map = {p.subsection_number: p for p in progress_result.scalars().all()}
    else:
        progress_map = {}
    
    # è½¬æ¢ä¸ºå“åº”æ ¼å¼
    subsection_list = []
    for subsection in subsections:
        # ä» map ä¸­æŸ¥æ‰¾è¿›åº¦
        subsection_progress = progress_map.get(subsection.subsection_number)
        
        is_completed = False
        progress_percentage = 0.0
        
        if subsection_progress:
            is_completed = subsection_progress.status == "completed"
            progress_percentage = subsection_progress.subsection_progress or 0.0
        
        subsection_list.append({
            "subsection_number": subsection.subsection_number,
            "subsection_title": subsection.subsection_title,
            "content_summary": subsection.content_summary,
            "estimated_time_minutes": subsection.estimated_time_minutes,
            "is_completed": is_completed,
            "progress": progress_percentage
        })
    
    return {
        "document_id": document_id,
        "chapter_number": chapter_number,
        "chapter_title": progress.chapter_title,
        "total_subsections": len(subsection_list),
        "subsections": subsection_list
    }


@router.delete("/{document_id}")
async def delete_document(
    document_id: int,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """
    åˆ é™¤æ–‡æ¡£
    """
    from sqlalchemy import select, delete
    from app.models.document import Document
    
    # éªŒè¯æ–‡æ¡£å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
    result = await db.execute(
        select(Document).where(Document.id == document_id)
    )
    document = result.scalar_one_or_none()
    
    if not document:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="æ–‡æ¡£ä¸å­˜åœ¨"
        )
    
    if document.uploaded_by != current_user.id:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="æ— æƒé™åˆ é™¤æ­¤æ–‡æ¡£"
        )
    
    # ğŸ”§ FIX: çº§è”åˆ é™¤ç›¸å…³æ•°æ®
    print(f"\n{'='*60}")
    print(f"ğŸ—‘ï¸  å¼€å§‹åˆ é™¤æ–‡æ¡£ {document_id} ({document.filename})")
    print(f"{'='*60}\n")

    from sqlalchemy import text

    # 0. å…ˆç»Ÿè®¡è¦åˆ é™¤çš„æ•°æ®
    print("ğŸ“Š ç»Ÿè®¡è¦åˆ é™¤çš„æ•°æ®:")
    stats_check = text("""
        SELECT
            (SELECT COUNT(*) FROM conversations WHERE document_id = :doc_id AND user_id = :user_id) as conversations,
            (SELECT COUNT(*) FROM progress WHERE document_id = :doc_id AND user_id = :user_id) as progress,
            (SELECT COUNT(*) FROM subsections WHERE document_id = :doc_id AND user_id = :user_id) as subsections
    """)
    stats = await db.execute(stats_check, {
        'doc_id': document_id,
        'user_id': current_user.id
    })
    row = stats.fetchone()
    print(f"   - å¯¹è¯è®°å½•: {row[0]} æ¡")
    print(f"   - å­¦ä¹ è¿›åº¦: {row[1]} æ¡")
    print(f"   - å°èŠ‚è®°å½•: {row[2]} æ¡")
    print()

    # 1. åˆ é™¤å¯¹è¯è®°å½• (conversations è¡¨)
    print("ğŸ—‘ï¸  æ­¥éª¤ 1/6: åˆ é™¤å¯¹è¯è®°å½•...")
    conversation_delete = text("""
        DELETE FROM conversations
        WHERE document_id = :document_id AND user_id = :user_id
    """)
    result = await db.execute(conversation_delete, {
        'document_id': document_id,
        'user_id': current_user.id
    })
    conversation_count = result.rowcount
    print(f"   âœ… åˆ é™¤äº† {conversation_count} æ¡å¯¹è¯è®°å½•")

    # 2. åˆ é™¤å­¦ä¹ è¿›åº¦è®°å½• (progress è¡¨) - å…ˆè·å–è¦åˆ é™¤çš„ progress_id
    progress_ids_query = text("""
        SELECT id FROM progress
        WHERE document_id = :document_id AND user_id = :user_id
    """)
    progress_result = await db.execute(progress_ids_query, {
        'document_id': document_id,
        'user_id': current_user.id
    })
    progress_ids = [row[0] for row in progress_result.fetchall()]

    # 3. åˆ é™¤æµ‹è¯•è®°å½• (quiz_attempts è¡¨) - é€šè¿‡ progress_id
    quiz_count = 0
    if progress_ids:
        # æ„å»º IN å­å¥
        placeholders = ','.join([f':pid{i}' for i in range(len(progress_ids))])
        params = {f'pid{i}': pid for i, pid in enumerate(progress_ids)}
        quiz_delete = text(f"""
            DELETE FROM quiz_attempts
            WHERE progress_id IN ({placeholders})
        """)
        quiz_result = await db.execute(quiz_delete, params)
        quiz_count = quiz_result.rowcount
        print(f"   âœ… åˆ é™¤äº† {quiz_count} æ¡æµ‹è¯•è®°å½•")

    # ç°åœ¨åˆ é™¤è¿›åº¦è®°å½•
    progress_delete = text("""
        DELETE FROM progress
        WHERE document_id = :document_id AND user_id = :user_id
    """)
    result = await db.execute(progress_delete, {
        'document_id': document_id,
        'user_id': current_user.id
    })
    progress_count = result.rowcount
    print(f"   âœ… åˆ é™¤äº† {progress_count} æ¡å­¦ä¹ è¿›åº¦è®°å½•")

    # 4. åˆ é™¤å°èŠ‚è®°å½• (subsections è¡¨)
    subsection_delete = text("""
        DELETE FROM subsections
        WHERE document_id = :document_id AND user_id = :user_id
    """)
    result = await db.execute(subsection_delete, {
        'document_id': document_id,
        'user_id': current_user.id
    })
    subsection_count = result.rowcount
    print(f"   âœ… åˆ é™¤äº† {subsection_count} æ¡å°èŠ‚è®°å½•")

    # 5. åˆ é™¤ ChromaDB ä¸­çš„å‘é‡é›†åˆ
    try:
        from app.core.chroma import delete_document_collection
        deleted = delete_document_collection(document.md5_hash)
        if deleted:
            print(f"   âœ… åˆ é™¤äº† ChromaDB å‘é‡é›†åˆ")
        else:
            print(f"   âš ï¸  ChromaDB é›†åˆä¸å­˜åœ¨")
    except Exception as e:
        print(f"   âš ï¸  åˆ é™¤ ChromaDB æ•°æ®å¤±è´¥: {e}")

    # 4. åˆ é™¤æ–‡æ¡£è®°å½•
    await db.execute(
        delete(Document).where(Document.id == document_id)
    )
    await db.commit()

    print(f"\n{'='*60}")
    print(f"âœ… æ–‡æ¡£åˆ é™¤å®Œæˆ")
    print(f"   æ–‡æ¡£ID: {document_id}")
    print(f"   æ–‡ä»¶å: {document.filename}")
    print(f"   å·²åˆ é™¤:")
    print(f"      - å¯¹è¯è®°å½•: {conversation_count} æ¡")
    print(f"      - æµ‹è¯•è®°å½•: {quiz_count} æ¡")
    print(f"      - å­¦ä¹ è¿›åº¦: {progress_count} æ¡")
    print(f"      - å°èŠ‚è®°å½•: {subsection_count} æ¡")
    print(f"{'='*60}\n")

    return {
        "message": "æ–‡æ¡£åˆ é™¤æˆåŠŸ",
        "document_id": document_id,
        "document_title": document.title,
        "deleted_records": {
            "conversations": conversation_count,
            "quiz_attempts": quiz_count,
            "progress": progress_count,
            "subsections": subsection_count
        }
    }


@router.get("/{document_id}/status")
async def get_document_status(
    document_id: int,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """
    è·å–æ–‡æ¡£å¤„ç†çŠ¶æ€å’Œè¿›åº¦

    è¿”å›è¯¦ç»†çš„å¤„ç†è¿›åº¦ï¼Œç”¨äºå‰ç«¯è½®è¯¢æ›´æ–°
    """
    from sqlalchemy import select, text

    # éªŒè¯æ–‡æ¡£å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
    result = await db.execute(
        select(Document).where(Document.id == document_id)
    )
    document = result.scalar_one_or_none()

    if not document:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="æ–‡æ¡£ä¸å­˜åœ¨"
        )

    if document.uploaded_by != current_user.id:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="æ— æƒé™è®¿é—®æ­¤æ–‡æ¡£"
        )

    # è·å–å¤„ç†çŠ¶æ€
    status_query = text("""
        SELECT
            id,
            filename,
            title,
            processing_status,
            has_text_layer,
            ocr_confidence,
            current_page,
            total_pages,
            total_chapters,
            uploaded_at
        FROM documents
        WHERE id = :document_id
    """)

    result = await db.execute(status_query, {'document_id': document_id})
    row = result.fetchone()

    if not row:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="æ–‡æ¡£çŠ¶æ€ä¿¡æ¯ä¸å­˜åœ¨"
        )

    # è§£æçŠ¶æ€
    status = row[3] or 'pending'
    has_text_layer = bool(row[4])
    ocr_confidence = row[5] or 0.0
    current_page = row[6] or 0
    total_pages = row[7] or 0
    total_chapters = row[8] or 0

    # è®¡ç®—è¿›åº¦ç™¾åˆ†æ¯”
    progress_percentage = 0
    stage = ""
    stage_message = ""

    if status == 'pending':
        progress_percentage = 0
        stage = "ç­‰å¾…å¤„ç†"
        stage_message = "æ–‡æ¡£å·²ä¸Šä¼ ï¼Œç­‰å¾…å¼€å§‹å¤„ç†..."

    elif status == 'processing':
        progress_percentage = 25
        stage = "æ­£åœ¨æå–æ–‡æœ¬"
        stage_message = "æ­£åœ¨ä»PDFä¸­æå–æ–‡æœ¬å†…å®¹..."

    elif status == 'ocr_processing':
        if total_pages > 0:
            progress_percentage = min(90, int((current_page / total_pages) * 100))
        else:
            progress_percentage = 50
        stage = "æ­£åœ¨OCRè¯†åˆ«"
        stage_message = f"æ­£åœ¨ä½¿ç”¨AIè¯†åˆ«ç¬¬ {current_page}/{total_pages} é¡µ..."

    elif status == 'completed':
        progress_percentage = 100
        stage = "å¤„ç†å®Œæˆ"
        stage_message = "æ–‡æ¡£å·²æˆåŠŸå¤„ç†å¹¶å¯ä»¥ä½¿ç”¨"

    elif status == 'failed':
        progress_percentage = 0
        stage = "å¤„ç†å¤±è´¥"
        stage_message = "æ–‡æ¡£å¤„ç†å¤±è´¥ï¼Œè¯·å°è¯•é‡æ–°ä¸Šä¼ æ›´æ¸…æ™°çš„æ–‡ä»¶"

    # æ„å»ºå“åº”
    response = {
        "document_id": document_id,
        "filename": row[1],
        "title": row[2],
        "status": status,
        "stage": stage,
        "stage_message": stage_message,
        "progress_percentage": progress_percentage,
        "has_text_layer": has_text_layer,
        "ocr_confidence": ocr_confidence,
        "current_page": current_page,
        "total_pages": total_pages,
        "total_chapters": total_chapters,
        "is_scan": not has_text_layer,
        "uploaded_at": row[10].isoformat() if row[10] else None
    }

    # æ·»åŠ æç¤ºä¿¡æ¯
    if status == 'completed' and not has_text_layer:
        response['warning'] = "æ­¤æ–‡æ¡£é€šè¿‡OCRè¯†åˆ«ï¼Œå»ºè®®æ ¸å¯¹ä¸“ä¸šæœ¯è¯­å’Œå…¬å¼"
        response['ocr_notice'] = "æ‰«æä»¶è¯†åˆ«å‡†ç¡®ç‡çº¦85-95%ï¼Œé‡è¦å†…å®¹è¯·æ‰‹åŠ¨æ ¸å¯¹"

    return response

