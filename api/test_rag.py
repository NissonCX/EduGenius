#!/usr/bin/env python3
"""
EduGenius RAG æµç¨‹æµ‹è¯•è„šæœ¬
æµ‹è¯•æ–‡æ¡£è§£æã€å‘é‡åŒ–ã€æ£€ç´¢çš„å®Œæ•´æµç¨‹
"""
import asyncio
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from app.services.document_processor import process_uploaded_document, DocumentProcessor
from app.core.chroma import (
    create_document_collection,
    add_document_chunks,
    search_documents,
    get_collection_stats
)
from app.core.config import settings


async def test_document_processing():
    """æµ‹è¯•æ–‡æ¡£å¤„ç†å®Œæ•´æµç¨‹"""
    print("=" * 60)
    print("ğŸ“‹ æµ‹è¯• 1: æ–‡æ¡£å¤„ç†æµç¨‹")
    print("=" * 60)

    # åˆ›å»ºä¸€ä¸ªæµ‹è¯• TXT æ–‡ä»¶
    test_file = "/tmp/test_document.txt"
    test_content = """
# ç¬¬ä¸€ç« ï¼šçº¿æ€§ä»£æ•°åŸºç¡€

## 1.1 å‘é‡çš„å®šä¹‰

å‘é‡æ˜¯çº¿æ€§ä»£æ•°ä¸­æœ€åŸºæœ¬çš„æ¦‚å¿µä¹‹ä¸€ã€‚ä»å‡ ä½•è§’åº¦çœ‹ï¼Œå‘é‡æ˜¯ä¸€ä¸ªæœ‰æ–¹å‘å’Œå¤§å°çš„é‡ã€‚åœ¨æ•°å­¦ä¸Šï¼Œå‘é‡å¯ä»¥è¡¨ç¤ºä¸ºä¸€ä¸ªæœ‰åºçš„æ•°ç»„ã€‚

### å‘é‡çš„è¡¨ç¤º
åœ¨äºŒç»´ç©ºé—´ä¸­ï¼Œå‘é‡å¯ä»¥è¡¨ç¤ºä¸º v = (x, y)
åœ¨ä¸‰ç»´ç©ºé—´ä¸­ï¼Œå‘é‡å¯ä»¥è¡¨ç¤ºä¸º v = (x, y, z)

## 1.2 å‘é‡çš„è¿ç®—

å‘é‡ä¹‹é—´å¯ä»¥è¿›è¡ŒåŠ æ³•å’Œæ•°ä¹˜è¿ç®—ã€‚

### å‘é‡åŠ æ³•
ä¸¤ä¸ªå‘é‡ç›¸åŠ ï¼šv + w = (vâ‚ + wâ‚, vâ‚‚ + wâ‚‚)

### æ•°ä¹˜
æ ‡é‡ä¹˜ä»¥å‘é‡ï¼škÂ·v = (kÂ·vâ‚, kÂ·vâ‚‚)

## 1.3 åº”ç”¨åœºæ™¯

çº¿æ€§ä»£æ•°åœ¨è®¡ç®—æœºå›¾å½¢å­¦ã€æœºå™¨å­¦ä¹ ã€ç‰©ç†å­¦ç­‰é¢†åŸŸæœ‰å¹¿æ³›åº”ç”¨ã€‚
"""

    with open(test_file, 'w', encoding='utf-8') as f:
        f.write(test_content)

    try:
        # å¤„ç†æ–‡æ¡£
        result = await process_uploaded_document(
            file_path=test_file,
            title="æµ‹è¯•æ–‡æ¡£.txt",
            user_email="test@edugenius.ai"
        )

        print(f"âœ… æ–‡æ¡£å¤„ç†æˆåŠŸï¼")
        print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯ï¼š")
        print(f"   - æ€» chunks: {result['stats']['total_chunks']}")
        print(f"   - æ€»å­—ç¬¦æ•°: {result['stats']['total_characters']}")
        print(f"   - å¹³å‡é•¿åº¦: {result['stats']['avg_chunk_length']:.1f}")
        print(f"   - å‘é‡ç»´åº¦: {result['stats']['embedding_dimension']}")
        print(f"   - MD5: {result['md5']}")
        print()

        # æµ‹è¯•å‘é‡åŒ–å­˜å‚¨
        print("=" * 60)
        print("ğŸ“‹ æµ‹è¯• 2: å‘é‡åŒ–å­˜å‚¨")
        print("=" * 60)

        md5_hash = result['md5']

        # åˆ›å»º ChromaDB collection
        create_document_collection(md5_hash)
        print(f"âœ… Collection åˆ›å»ºæˆåŠŸ: doc_{md5_hash[:8]}...")

        # æ·»åŠ  chunks
        chunks = result['chunks']
        embeddings = result['embeddings']
        chunk_texts = result['texts']
        chunk_metadata = [chunk.metadata for chunk in chunks]

        add_document_chunks(
            md5_hash=md5_hash,
            chunks=chunk_texts,
            embeddings=embeddings,
            metadata=chunk_metadata
        )
        print(f"âœ… æ·»åŠ äº† {len(chunks)} ä¸ª chunks åˆ° ChromaDB")

        # è·å–ç»Ÿè®¡
        stats = get_collection_stats(md5_hash)
        if stats:
            print(f"ğŸ“Š Collection ç»Ÿè®¡: {stats['count']} ä¸ªå‘é‡")
        print()

        # æµ‹è¯•æ£€ç´¢
        print("=" * 60)
        print("ğŸ“‹ æµ‹è¯• 3: RAG æ£€ç´¢")
        print("=" * 60)

        query = "ä»€ä¹ˆæ˜¯å‘é‡ï¼Ÿ"
        print(f"ğŸ” æŸ¥è¯¢: {query}")

        try:
            retrieved_docs = search_documents(
                query_text=query,
                md5_hash=md5_hash,
                embedding_model=None,
                n_results=2
            )

            print(f"âœ… æ£€ç´¢åˆ° {len(retrieved_docs)} ä¸ªç›¸å…³ç‰‡æ®µï¼š")
            for i, doc in enumerate(retrieved_docs, 1):
                print(f"\nç‰‡æ®µ {i} (ç›¸ä¼¼åº¦: {1 - doc['distance']:.2f}):")
                print(f"  {doc['content'][:100]}...")
                if doc.get('metadata'):
                    print(f"  å…ƒæ•°æ®: {doc['metadata']}")

        except Exception as e:
            print(f"âŒ æ£€ç´¢å¤±è´¥: {e}")

        print()
        return True

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

    finally:
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        if os.path.exists(test_file):
            os.remove(test_file)


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("\n")
    print("ğŸš€ EduGenius RAG æµç¨‹æµ‹è¯•")
    print("=" * 60)
    print()

    # æ£€æŸ¥é…ç½®
    if not settings.DASHSCOPE_API_KEY:
        print("âŒ é”™è¯¯: DASHSCOPE_API_KEY æœªè®¾ç½®")
        return

    print(f"âœ… é…ç½®æ£€æŸ¥é€šè¿‡")
    print(f"ğŸ“Š ä½¿ç”¨æ¨¡å‹: {settings.DEFAULT_MODEL}")
    print()

    # è¿è¡Œæµ‹è¯•
    success = await test_document_processing()

    # æ€»ç»“
    print("=" * 60)
    print("ğŸ“Š æµ‹è¯•æ€»ç»“")
    print("=" * 60)

    if success:
        print("ğŸ‰ RAG æµç¨‹æµ‹è¯•é€šè¿‡ï¼")
        print("\nåŠŸèƒ½éªŒè¯ï¼š")
        print("âœ… æ–‡æ¡£è§£æï¼ˆTXTï¼‰")
        print("âœ… è¯­ä¹‰åˆ‡åˆ†")
        print("âœ… DashScope Embedding")
        print("âœ… ChromaDB å‘é‡å­˜å‚¨")
        print("âœ… è¯­ä¹‰æ£€ç´¢ï¼ˆRAGï¼‰")
        print("\nä¸‹ä¸€æ­¥ï¼š")
        print("1. ä¿®æ”¹ teaching.py API ç«¯ç‚¹ï¼Œé›†æˆ RAG åˆ°å¯¹è¯æµç¨‹")
        print("2. æµ‹è¯•å®Œæ•´çš„ä¸Šä¼ â†’å¯¹è¯æµç¨‹")
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®å’Œç½‘ç»œ")


if __name__ == "__main__":
    asyncio.run(main())
